{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handson_ml_chapter 17.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOCSlbJwL6+AlW7OHfe4tW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/handson_ml_2/blob/main/Handson_ml_chapter_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUipIQM7Xr97"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version은 코랩에서만 동작합니다.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"런타임 > 런타임 유형 변경 메뉴를 선택하고 하드웨어 가속기로 GPU를 고르세요.\")\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"autoencoders\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "zvkgNddcX6cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angles = np.random.rand(3) * 3 * np.pi / 2 - 0.5"
      ],
      "metadata": {
        "id": "g-N29JlDY9te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.empty((60,3))"
      ],
      "metadata": {
        "id": "9vS5x4T3aoA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 선형 오토인코더로 PCA 수행하기"
      ],
      "metadata": {
        "id": "xDis55WRYGHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make 3d dataset\n",
        "np.random.seed(4)\n",
        "\n",
        "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
        "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "    data = np.empty((m,3))\n",
        "    data[:,0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "    data[:,1] = np.sin(angles) + 0.7 + noise * np.random.randn(m) / 2\n",
        "    data[:,2] = data[:,0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
        "    return data\n",
        "\n",
        "X_train = generate_3d_data(60)\n",
        "X_train = X_train - X_train.mean(axis=0, keepdims=0)"
      ],
      "metadata": {
        "id": "Fy-9cOQgYKFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "1AdWKaSHbLRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make autoencoder\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
        "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
        "autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1.5))"
      ],
      "metadata": {
        "id": "D3vDepfAbPOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=20)"
      ],
      "metadata": {
        "id": "t5I509KIbxWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codings = encoder.predict(X_train)"
      ],
      "metadata": {
        "id": "LcsNe5lacNIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(4,3))\n",
        "plt.plot(codings[:,0], codings[:,1], \"b.\")\n",
        "plt.xlabel(\"$z_1$\", fontsize=18)\n",
        "plt.ylabel('$z_2$', fontsize=18, rotation=0)\n",
        "plt.grid(True)\n",
        "save_fig('linear_autoencoder_pca_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A0OX1_aFcTef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 적층 오토인코더"
      ],
      "metadata": {
        "id": "tLXgQQ7ccxCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "h8muJJsed4Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rounded_accuracy(y_true, y_pred):\n",
        "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
      ],
      "metadata": {
        "id": "-yqEOSgYcyBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "stacked_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(30, activation='selu'),\n",
        "])\n",
        "\n",
        "stacked_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[30]),\n",
        "    # mnist 데이터를 / 255 햇기 때문에 \n",
        "    keras.layers.Dense(28 * 28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "stacked_ae.compile(loss='binary_crossentropy',\n",
        "                   optimizer = keras.optimizers.SGD(learning_rate=1.5), metrics=[rounded_accuracy])\n",
        "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
        "                         validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "kD62R1vBdGpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_reconstructions(model, images=X_valid, n_images=5):\n",
        "    reconstructions = model.predict(images[:n_images])\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plot_image(images[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plot_image(reconstructions[image_index])"
      ],
      "metadata": {
        "id": "_wDoW85JfwEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(stacked_ae)\n",
        "save_fig('reconstruction_plot')"
      ],
      "metadata": {
        "id": "LjTLvol1gbYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패션 MNIST 시각화 하기"
      ],
      "metadata": {
        "id": "7adfHL-cggme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
        "tsne = TSNE()\n",
        "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
        "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
      ],
      "metadata": {
        "id": "SC_XLM8Ygojn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_valid_2D[:,0], X_valid_2D[:,1], c=y_valid, s=10, cmap='tab10')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2PJIuQd7hDD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "cmap = plt.cm.tab10\n",
        "plt.scatter(X_valid_2D[:,0], X_valid_2D[:,1], c=y_valid, s=10, cmap=cmap)\n",
        "image_positions = np.array([[1.,1.]])\n",
        "\n",
        "for index, position in enumerate(X_valid_2D):\n",
        "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
        "    if np.min(dist) > 0.02:\n",
        "        image_positions = np.r_[image_positions, [position]]\n",
        "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "            mpl.offsetbox.OffsetImage(X_valid[index], cmap='binary'),\n",
        "            position, bboxprops = {\"edgecolor\":cmap(y_valid[index]), 'lw':2})\n",
        "        plt.gca().add_artist(imagebox)\n",
        "\n",
        "plt.axis('off')\n",
        "save_fig('fashion_mnist_visualization_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xGzNfTrfhXai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가중치 묶기"
      ],
      "metadata": {
        "id": "rHcSLYtHitV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더의 가중치를 저치하여 디코더의 가중치로 사용\n",
        "class DenseTranspose(keras.layers.Layer):\n",
        "    def __init__(self,dense,activation=None, **kwargs):\n",
        "        self.dense = dense\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        super().__init__(**kwargs)\n",
        "    \n",
        "    def build(self, batch_input_shape):\n",
        "        self.biases = self.add_weight(name='bias',\n",
        "                                      shape=[self.dense.input_shape[-1]],\n",
        "                                      initializer='zeros')\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
        "        return self.activation(z + self.biases)"
      ],
      "metadata": {
        "id": "8qo64paeiuQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "dense_1 = keras.layers.Dense(100, activation='selu')\n",
        "dense_2 = keras.layers.Dense(30, activation='selu')\n",
        "\n",
        "tied_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    dense_1,\n",
        "    dense_2\n",
        "])\n",
        "\n",
        "tied_decoder = keras.models.Sequential([\n",
        "    DenseTranspose(dense_2, activation='selu'),\n",
        "    DenseTranspose(dense_1, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])\n",
        "\n",
        "tied_ae.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1.5), metrics=[rounded_accuracy])\n",
        "history = tied_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "WA3cVwygkend"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(tied_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s09obpO0mPOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한 번에 하나의 오토인코더 훈련하기"
      ],
      "metadata": {
        "id": "zGpAt0YFpYqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_autoencoder(n_neurons, X_train, X_valid, loss, optimizer,\n",
        "                      n_epochs=10, output_activation=None, metrics=None):\n",
        "    n_inputs = X_train.shape[-1]\n",
        "    encoder = keras.models.Sequential([\n",
        "        keras.layers.Dense(n_neurons, activation='selu', input_shape=[n_inputs])\n",
        "    ])\n",
        "    decoder = keras.models.Sequential([\n",
        "        keras.layers.Dense(n_inputs,activation=output_activation),\n",
        "    ])\n",
        "\n",
        "    autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "    autoencoder.compile(optimizer, loss, metrics=metrics)\n",
        "    autoencoder.fit(X_train, X_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, X_valid))\n",
        "    \n",
        "    return encoder, decoder, encoder(X_train), encoder(X_valid)"
      ],
      "metadata": {
        "id": "HMhDR1mspcT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "K = keras.backend\n",
        "X_train_flat = K.batch_flatten(X_train)\n",
        "X_valid_flat = K.batch_flatten(X_valid)\n",
        "enc1, dec1, X_train_enc1, X_valid_enc1 = train_autoencoder(\n",
        "    100, X_train_flat, X_valid_flat, 'binary_crossentropy',\n",
        "    keras.optimizers.SGD(learning_rate=1.5), output_activation='sigmoid',\n",
        "    metrics=[rounded_accuracy])\n",
        "\n",
        "enc2, dec2, _, _ = train_autoencoder(\n",
        "    30, X_train_enc1, X_valid_enc1, \"mse\", keras.optimizers.SGD(learning_rate=0.05),\n",
        "    output_activation='selu')"
      ],
      "metadata": {
        "id": "omnx3G65qM9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_ae_1_by_1 = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    enc1, enc2, dec2, dec1,\n",
        "    keras.layers.Reshape([28,28])\n",
        "])"
      ],
      "metadata": {
        "id": "NCX86jFHr3Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(stacked_ae_1_by_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z63xAjWrsc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_ae_1_by_1.compile(loss='binary_crossentropy',\n",
        "                          optimizer=keras.optimizers.SGD(learning_rate=0.1), metrics=[rounded_accuracy])\n",
        "history = stacked_ae_1_by_1.fit(X_train, X_train, epochs=10,\n",
        "                                validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "Mg5aFojXsg4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(stacked_ae_1_by_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmtFKaRhs47X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 밀집 층 대신에 합성곱 층 사용하기"
      ],
      "metadata": {
        "id": "sdt3bqDFtRxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2)\n",
        "])\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\",\n",
        "                                 input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "\n",
        "conv_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
        "                metrics=[rounded_accuracy])\n",
        "history = conv_ae.fit(X_train, X_train, epochs=5,\n",
        "                      validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "xl5K6zX3tyat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder.summary()\n",
        "conv_decoder.summary()"
      ],
      "metadata": {
        "id": "NaoF9N3pxKsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(conv_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hz35-9U3xTU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 오토인코더"
      ],
      "metadata": {
        "id": "H_7BBsNXxbpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recurrent_encoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(100, return_sequences=True, input_shape=[28, 28]),\n",
        "    keras.layers.LSTM(30)\n",
        "])\n",
        "recurrent_decoder = keras.models.Sequential([\n",
        "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
        "    keras.layers.LSTM(100, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
        "])\n",
        "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
        "recurrent_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(0.1),\n",
        "                     metrics=[rounded_accuracy])"
      ],
      "metadata": {
        "id": "ke7a4zQpxdj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = recurrent_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "oYm8v7FOC4s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(recurrent_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cZnIJjDaC6vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 적층 잡음 제거 오토인코더"
      ],
      "metadata": {
        "id": "527ka62KDxPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "denoising_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.GaussianNoise(0.2),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(30, activation='selu')\n",
        "])\n",
        "\n",
        "denoising_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[30]),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n",
        "denoising_ae.compile(loss='binary_crossentropy',optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
        "                      metrics=[rounded_accuracy])\n",
        "\n",
        "history = denoising_ae.fit(X_train, X_train, epochs=50,\n",
        "                           validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "TZmlv0WmDy14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = keras.layers.GaussianNoise(0.2)\n",
        "show_reconstructions(denoising_ae, noise(X_valid, training=True))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-sSWOMMXEzjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃 사용\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "dropout_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(30, activation='selu')\n",
        "])\n",
        "\n",
        "dropout_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[30]),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
        "dropout_ae.compile(loss='binary_crossentropy',optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
        "                   metrics=[rounded_accuracy])\n",
        "history = dropout_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "_BiQi5aaFHl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "dropout = keras.layers.Dropout(0.5)\n",
        "show_reconstructions(dropout_ae, dropout(X_valid, training=True))\n",
        "save_fig(\"dropout_denoising_plot\", tight_layout=True)"
      ],
      "metadata": {
        "id": "2IXssBnWGPZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 희소 오토인코더"
      ],
      "metadata": {
        "id": "TCO-CSGNGrOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "simple_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(30, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "simple_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[30]),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "simple_ae = keras.models.Sequential([simple_encoder, simple_decoder])\n",
        "simple_ae.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1.),\n",
        "                  metrics=[rounded_accuracy])\n",
        "\n",
        "history = simple_ae.fit(X_train, X_train, epochs=10,\n",
        "                        validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "-w09r9UnGsJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(simple_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nN74GBacIehd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_percent_hist(ax, data, bins):\n",
        "    counts, _ = np.histogram(data, bins=bins)\n",
        "    widths = bins[1:] - bins[:-1]\n",
        "    x = bins[:-1] + widths / 2\n",
        "    ax.bar(x, counts / len(data), width=widths*0.8 )\n",
        "    ax.xaxis.set_ticks(bins)\n",
        "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(\n",
        "        lambda y, position: \"{}%\".format(int(np.round(100*y)))))\n",
        "    ax.grid(True)"
      ],
      "metadata": {
        "id": "GMf5u4fYIjqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_activations_histogram(encoder, height=1, n_bins=10):\n",
        "    X_valid_codings = encoder(X_valid).numpy()\n",
        "    activation_means = X_valid_codings.mean(axis=0)\n",
        "    mean = activation_means.mean()\n",
        "    bins = np.linspace(0,1, n_bins + 1)\n",
        "\n",
        "    fig, [ax1, ax2] = plt.subplots(figsize=(10,3), nrows=1, ncols=2, sharey=True)\n",
        "    plot_percent_hist(ax1, X_valid_codings.ravel(), bins)\n",
        "    ax1.plot([mean, mean], [0, height],'k--', label='Overall Mean = {:.2f}'.format(mean))\n",
        "    ax1.legend(loc='upper center', fontsize=14)\n",
        "    ax1.set_xlabel('Activation')\n",
        "    ax1.set_ylabel('% Activations')\n",
        "    ax1.axis([0,1,0,height])\n",
        "    plot_percent_hist(ax2, activation_means, bins)\n",
        "    ax2.plot([mean, mean],[0, height], \"k--\")\n",
        "    ax2.set_xlabel(\"Neuron Mean Activation\")\n",
        "    ax2.set_ylabel(\"% Neurons\")\n",
        "    ax2.axis([0,1,0, height])"
      ],
      "metadata": {
        "id": "k2xBYj5eJJPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_activations_histogram(simple_encoder, height=0.35)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "huqT9wIzLVJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "sparse_l1_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(300, activation='sigmoid'),\n",
        "    keras.layers.ActivityRegularization(l1=1e-3)\n",
        "])\n",
        "\n",
        "sparse_l1_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[300]),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])\n",
        "sparse_l1_ae.compile(loss='binary_crossentropy',optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
        "                     metrics=[rounded_accuracy])\n",
        "\n",
        "history = sparse_l1_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "jBVwQ-c0LbJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(sparse_l1_ae)"
      ],
      "metadata": {
        "id": "QOO-XOH3IXOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_activations_histogram(sparse_l1_encoder, height=1.)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G0MOTQO9Ipme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.1\n",
        "q = np.linspace(0.001, 0.999, 500)\n",
        "kl_div = p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q))\n",
        "mse = (p - q)**2\n",
        "mae = np.abs(p - q)\n",
        "plt.plot([p, p], [0, 0.3], \"k:\")\n",
        "plt.text(0.05, 0.32, \"Target\\nsparsity\", fontsize=14)\n",
        "plt.plot(q, kl_div, \"b-\", label=\"KL divergence\")\n",
        "plt.plot(q, mae, \"g--\", label=r\"MAE ($\\ell_1$)\")\n",
        "plt.plot(q, mse, \"r--\", linewidth=1, label=r\"MSE ($\\ell_2$)\")\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.xlabel(\"Actual sparsity\")\n",
        "plt.ylabel(\"Cost\", rotation=0)\n",
        "plt.axis([0, 1, 0, 0.95])\n",
        "save_fig(\"sparsity_loss_plot\")"
      ],
      "metadata": {
        "id": "VI5F_EeII09d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "kl_divergence = keras.losses.kullback_leibler_divergence\n",
        "\n",
        "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight, target=0.1):\n",
        "        self.weight = weight\n",
        "        self.target = target\n",
        "    def __call__(self, inputs):\n",
        "        mean_activities = K.mean(inputs, axis=0)\n",
        "        return self.weight * (\n",
        "            kl_divergence(self.target, mean_activities) +\n",
        "            kl_divergence(1. - self.target, 1. - mean_activities))"
      ],
      "metadata": {
        "id": "6Xg6RVtcKEOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
        "sparse_kl_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n",
        "])\n",
        "sparse_kl_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n",
        "sparse_kl_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
        "              metrics=[rounded_accuracy])\n",
        "history = sparse_kl_ae.fit(X_train, X_train, epochs=10,\n",
        "                           validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "5aLDuFhYK0c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(sparse_kl_ae)"
      ],
      "metadata": {
        "id": "-mPBrNGCL8oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_activations_histogram(sparse_kl_encoder)\n",
        "save_fig('sparse_autoencoder_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "umLxFgaJMWw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 변이형 오토인코더"
      ],
      "metadata": {
        "id": "UFLQD0RFMp45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
      ],
      "metadata": {
        "id": "sNsrynotMrN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_size = 10\n",
        "\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(codings_size)(z)\n",
        "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "variational_encoder = keras.models.Model(\n",
        "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "_, _, codings = variational_encoder(inputs)\n",
        "reconstructions = variational_decoder(codings)\n",
        "variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "latent_loss = -0.5 * K.sum(\n",
        "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
        "    axis=-1)\n",
        "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
        "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[rounded_accuracy])\n",
        "history = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,\n",
        "                             validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "dF-Ge4v_M5d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(variational_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0eFcgOYR3FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패션 이미지 생성하기"
      ],
      "metadata": {
        "id": "8GW_erqCDdGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap='binary')\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "KzGn8gWODeGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "codings = tf.random.normal(shape=[12, codings_size])\n",
        "images = variational_decoder(codings).numpy()\n",
        "plot_multiple_images(images, 4)\n",
        "save_fig('vae_generated_images_plot',tight_layout=False)"
      ],
      "metadata": {
        "id": "vef0okEXEp6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_grid = tf.reshape(codings, [1,3,4,codings_size])\n",
        "larger_grid = tf.image.resize(codings_grid, size=[5,7])\n",
        "interpolated_codings = tf.reshape(larger_grid, [-1, codings_size])\n",
        "images = variational_decoder(interpolated_codings).numpy()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "for index, image in enumerate(images):\n",
        "    plt.subplot(5,7,index + 1)\n",
        "    if index%7%2==0 and index//7%2==0:\n",
        "        plt.gca().get_xaxis().set_visible(False)\n",
        "        plt.gca().get_yaxis().set_visible(False)\n",
        "\n",
        "    else:\n",
        "        plt.axis('off')\n",
        "    plt.imshow(image, cmap='binary')\n",
        "\n",
        "save_fig('semantic_interpolation_plot', tight_layout=False)\n"
      ],
      "metadata": {
        "id": "wunAXBr0FRN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생성적 적대 신경망"
      ],
      "metadata": {
        "id": "Z9lLlBbQGle0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation='selu'),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(150, activation='selu'),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "metadata": {
        "id": "ycHzaTgcGnRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')"
      ],
      "metadata": {
        "id": "645kX6hhInYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "metadata": {
        "id": "Nx7C7CT2I6Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=10):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
        "        for X_batch in dataset:\n",
        "            # phase 1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase 2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        plot_multiple_images(generated_images, 8)                     # not shown\n",
        "        plt.show()       "
      ],
      "metadata": {
        "id": "_mEGhq3yJKWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
      ],
      "metadata": {
        "id": "nituALzpK3EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig('gan_generated_images_plot', tight_layout=False)"
      ],
      "metadata": {
        "id": "0ZxzxlONK7rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "metadata": {
        "id": "-j14h35QLZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 합성곱 GAN"
      ],
      "metadata": {
        "id": "vscRwMf5Lip2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_size = 100\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7*7*128, input_shape=[codings_size]),\n",
        "    keras.layers.Reshape([7,7,128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding='SAME',\n",
        "                                 activation='selu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1,kernel_size=5, strides=2, padding='SAME',\n",
        "                                activation='tanh'),\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding='SAME',\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28,28,1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding='SAME',\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "metadata": {
        "id": "gS4s2KXNLj3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')"
      ],
      "metadata": {
        "id": "VgEJPCzSPWi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dcgan = X_train.reshape(-1, 28,28,1)*2. -1."
      ],
      "metadata": {
        "id": "_NMwBdmcPoez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "metadata": {
        "id": "JSreiroHPtBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "metadata": {
        "id": "15aLSZLIQFR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig('dcgan_generated_images-plot', tight_layout=False)"
      ],
      "metadata": {
        "id": "L0ZK0T-nQILZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 자료\n",
        "<h2>  이진 오토인코더를 사용한 해싱"
      ],
      "metadata": {
        "id": "wZzoYKYyYQys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full),(X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "pcjNOmRoYWKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "hashing_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.GaussianNoise(15.),\n",
        "    keras.layers.Dense(16, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "hashing_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation='selu', input_shape=[16]),\n",
        "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
        "    keras.layers.Reshape([28,28])\n",
        "])\n",
        "\n",
        "hashing_ae = keras.models.Sequential([hashing_encoder, hashing_decoder])\n",
        "hashing_ae.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Nadam(),\n",
        "                   metrics=[rounded_accuracy])\n",
        "\n",
        "history = hashing_ae.fit(X_train, X_train, epochs=10,\n",
        "                         validation_data=(X_valid, X_valid))"
      ],
      "metadata": {
        "id": "AjuKVkbnY1T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_reconstructions(hashing_ae)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Md3aa2GVbp2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_activations_histogram(hashing_encoder)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mlqFIoCWcHS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashes = np.round(hashing_encoder.predict(X_valid)).astype(np.int32)\n",
        "hashes += np.array([[2**bit for bit in range(16)]])\n",
        "hashes = hashes.sum(axis=1)\n",
        "\n",
        "for h in hashes[:5]:\n",
        "    print(\"{:16b}\".format(h))\n",
        "print(\"...\")"
      ],
      "metadata": {
        "id": "drj5evxFcMkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "n_hashes = 10\n",
        "n_images = 8\n",
        "\n",
        "top_hashes = Counter(hashes).most_common(n_hashes)\n",
        "\n",
        "plt.figure(figsize=(n_images, n_hashes))\n",
        "\n",
        "for hash_index, (image_hash, hash_count) in enumerate(top_hashes):\n",
        "    indices = (hashes == image_hash)\n",
        "\n",
        "    for index, image in enumerate(X_valid[indices][:n_images]):\n",
        "        plt.subplot(n_hashes, n_images, hash_index * n_images + index + 1)\n",
        "        plt.imshow(image, cmap='binary')\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "nz4oK3zZcVGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 연습문제 해담\n",
        "<h3> 9."
      ],
      "metadata": {
        "id": "s7_quoyYgk7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[X_train, y_train], [X_test, y_test] = keras.datasets.cifar10.load_data()\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "B7j6xoMYgn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "wCjSm3f5jKEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "metadata": {
        "id": "Fh7Eb852jSeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "denoising_encoder = keras.models.Sequential([\n",
        "    keras.layers.GaussianNoise(0.1, input_shape=[32, 32, 3]),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation=\"relu\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Vxre39hfgw6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoising_encoder.summary()"
      ],
      "metadata": {
        "id": "X0f8useLhmS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "denoising_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(16 * 16 * 32, activation=\"relu\", input_shape=[512]),\n",
        "    keras.layers.Reshape([16, 16, 32]),\n",
        "    keras.layers.Conv2DTranspose(filters=3, kernel_size=3, strides=2,\n",
        "                                 padding=\"same\", activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "fZnjL70ihpVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoising_decoder.summary()"
      ],
      "metadata": {
        "id": "eQeqJBD1iESM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n",
        "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Nadam(),\n",
        "                     metrics=[\"mse\"])\n",
        "history = denoising_ae.fit(X_train, X_train, epochs=10,\n",
        "                           validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "id": "x6vmBFv2iI28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images = 5\n",
        "new_images = X_test[:n_images]\n",
        "new_iamges_noisy = new_images + np.random.randn(n_images, 32,32,3) * 0.1\n",
        "new_images_denoised = denoising_ae.predict(new_iamges_noisy)"
      ],
      "metadata": {
        "id": "1u7Zv9QIimip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images = 5\n",
        "new_images = X_test[:n_images]\n",
        "new_images_noisy = new_images + np.random.randn(n_images, 32, 32, 3) * 0.1\n",
        "new_images_denoised = denoising_ae.predict(new_images_noisy)\n",
        "\n",
        "plt.figure(figsize=(6, n_images * 2))\n",
        "for index in range(n_images):\n",
        "    plt.subplot(n_images, 3, index * 3 + 1)\n",
        "    plt.imshow(new_images[index])\n",
        "    plt.axis('off')\n",
        "    if index == 0:\n",
        "        plt.title(\"Original\")\n",
        "    plt.subplot(n_images, 3, index * 3 + 2)\n",
        "    plt.imshow(np.clip(new_images_noisy[index], 0., 1.))\n",
        "    plt.axis('off')\n",
        "    if index == 0:\n",
        "        plt.title(\"Noisy\")\n",
        "    plt.subplot(n_images, 3, index * 3 + 3)\n",
        "    plt.imshow(new_images_denoised[index])\n",
        "    plt.axis('off')\n",
        "    if index == 0:\n",
        "        plt.title(\"Denoised\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XWkQ7xY3mQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wHXJcVucmUu7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}