{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handson_ml chapter14.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuciMUrY5mzvNHAGUfjldn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/handson_ml_2/blob/main/handson_ml_chapter14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPAY6ljMQjiC"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 코랩에서 실행되는 노트북인가요?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"감지된 GPU가 없습니다. GPU가 없으면 CNN은 매우 느릴 수 있습니다.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"런타임 > 런타임 유형 변경 메뉴를 선택하고 하드웨어 가속기로 GPU를 고르세요.\")\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"cnn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "\n",
        "def plot_color_iamge(image):\n",
        "    plt.imshow(image, interpolation='nearest')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "y7BUyMMmQv3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "china = load_sample_image('china.jpg') / 255\n",
        "flower = load_sample_image('flower.jpg') / 255"
      ],
      "metadata": {
        "id": "w8jrIscnRD9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array([china,flower])\n",
        "batch_size, height, width, channels= images.shape"
      ],
      "metadata": {
        "id": "4IOQt035RP09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "LTF1awJwRb49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = np.zeros(shape=(7,7,channels,2), dtype=np.float32)"
      ],
      "metadata": {
        "id": "vEsZtRfARd_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters.shape"
      ],
      "metadata": {
        "id": "ixPRxvBMXKHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters[:,3,:,0] = 1\n",
        "filters[3,:,:,1] = 1"
      ],
      "metadata": {
        "id": "kgX7vc5rXMls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(filters[:,:,:,0])"
      ],
      "metadata": {
        "id": "I2BzW710ZRhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")"
      ],
      "metadata": {
        "id": "GXrNYA6xXb1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "id": "GZTmt-OFZkMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(outputs[0,:,:,1],cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0js4MedXcU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(outputs[0,:,:,0],cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xcadcfFlX2ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_index in (0,1):\n",
        "    for feature_map_index in (0,1):\n",
        "        plt.subplot(2,2,image_index*2 + feature_map_index + 1)\n",
        "        plot_image(outputs[image_index,:,:,feature_map_index])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FdIGPGCzYIeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop(images):\n",
        "    return images[150:220, 130:250]"
      ],
      "metadata": {
        "id": "nsEWX6V9YkEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_image(crop(images[0,:,:,0]))\n",
        "save_fig('china_original',tight_layout=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7d6EPkxjYvag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feature_map_index, filename in enumerate(['china_vertical','china_horizontal']):\n",
        "    plot_image(crop(outputs[0,:,:,feature_map_index]))\n",
        "    save_fig(filename, tight_layout=False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xIO0xY5_Y4M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 층"
      ],
      "metadata": {
        "id": "i2HGOdg2aVqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "conv = keras.layers.Conv2D(filters=2, kernel_size=7, strides=1,\n",
        "                           padding=\"SAME\", activation='relu',input_shape=outputs.shape)"
      ],
      "metadata": {
        "id": "flcaX_uUaXBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_outputs = conv(images)\n",
        "conv_outputs.shape"
      ],
      "metadata": {
        "id": "XHxN5Tl1akkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for image_index in (0,1):\n",
        "    for feature_map_index in(0,1):\n",
        "        plt.subplot(2,2,image_index*2+feature_map_index + 1)\n",
        "        plot_image(crop(conv_outputs[image_index,:,:,feature_map_index]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NkHpWiBRaoSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv.set_weights([filters, np.zeros(2)])"
      ],
      "metadata": {
        "id": "UVxGo0eFbDVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_outputs = conv(images)\n",
        "conv_outputs.shape"
      ],
      "metadata": {
        "id": "xCJiQziVbRt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for image_index in (0,1):\n",
        "    for feature_map_index in (0,1):\n",
        "        plt.subplot(2,2,image_index*2 + feature_map_index + 1)\n",
        "        plot_image(crop(conv_outputs[image_index,:,:,feature_map_index]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TnkBkQxgbUtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valid vs SAME 패딩"
      ],
      "metadata": {
        "id": "pWncqM9eb3VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_map_size(input_size, kernel_size, strides=1, padding=\"SAME\"):\n",
        "    if padding == \"SAME\":\n",
        "        return (input_size - 1) // strides + 1\n",
        "    else:\n",
        "        return (input_size - kernel_size) // strides + 1"
      ],
      "metadata": {
        "id": "K_nY9nDtb5B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_before_and_padded_size(input_size, kernel_size, strides=1):\n",
        "    fmap_size = feature_map_size(input_size, kernel_size, strides)\n",
        "    padded_size = max((fmap_size - 1) * strides + kernel_size, input_size)\n",
        "    pad_before = (padded_size - input_size) // 2\n",
        "    return pad_before, padded_size"
      ],
      "metadata": {
        "id": "bfenVqOKcFQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_same_padding(images, kernel_size, strides=1):\n",
        "    if kernel_size == 1:\n",
        "        return images.astype(np.float32)\n",
        "    \n",
        "    batch_size, height, width, channels = images.shape\n",
        "    top_pad, padded_height = pad_before_and_padded_size(height, kernel_size, strides)\n",
        "    left_pad, padded_width = pad_before_and_padded_size(width, kernel_size, strides)\n",
        "\n",
        "    padded_shape = [batch_size, padded_height, padded_width, channels]\n",
        "    padded_images = np.zeros(padded_shape, dtype=np.float32)\n",
        "    padded_images[:,top_pad:height+top_pad, left_pad:width+left_pad, :] = images\n",
        "    return padded_images"
      ],
      "metadata": {
        "id": "VBX0LWp9c7-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 7\n",
        "strides = 2\n",
        "\n",
        "conv_valid = keras.layers.Conv2D(filters=1, kernel_size=kernel_size, strides=strides, padding='VALID')\n",
        "conv_same = keras.layers.Conv2D(filters=1, kernel_size=kernel_size, strides=strides, padding=\"SAME\")\n",
        "\n",
        "valid_output = conv_valid(manual_same_padding(images,kernel_size, strides))\n",
        "\n",
        "conv_same.build(tf.TensorShape(images.shape))\n",
        "\n",
        "conv_same.set_weights(conv_valid.get_weights())\n",
        "\n",
        "same_output = conv_same(images.astype(np.float32))\n",
        "\n",
        "assert np.allclose(valid_output.numpy(), same_output.numpy())"
      ],
      "metadata": {
        "id": "IKA6m8WjYHyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 풀링층"
      ],
      "metadata": {
        "id": "eojeUuf7ZA53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 풀링\n",
        "max_pool = keras.layers.MaxPool2D(pool_size=2)"
      ],
      "metadata": {
        "id": "bY3OIjdnZCWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_images = np.array([crop(image) for image in images], dtype=np.float32)\n",
        "output = max_pool(cropped_images)"
      ],
      "metadata": {
        "id": "YOPTNenDZHMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[2, 1])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[0])  # 첫 번째 이미지 그리기\n",
        "ax1.axis(\"off\")\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output[0])  # 첫 번째 이미지 출력 그리기\n",
        "ax2.axis(\"off\")\n",
        "save_fig(\"china_max_pooling\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Zz6i42nZVSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 깊은 방향 풀링\n",
        "class DepthMaxPool(keras.layers.Layer):\n",
        "    def __init__(self, pool_size, strides=None, padding=\"VALID\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        if strides is None:\n",
        "            strides = pool_size\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.max_pool(inputs,\n",
        "                              ksize=(1,1,1,self.pool_size),\n",
        "                              strides=(1,1,1,self.pool_size),\n",
        "                              padding=self.padding)"
      ],
      "metadata": {
        "id": "c4oHfa7Obfrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth_pool = DepthMaxPool(3)\n",
        "with tf.device(\"/cpu:0\"): # 아직 GPU 커널이 없습니다.\n",
        "    depth_output = depth_pool(cropped_images)\n",
        "depth_output.shape"
      ],
      "metadata": {
        "id": "m5oejK34dROM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth_pool = keras.layers.Lambda(lambda X:tf.nn.max_pool(\n",
        "    X, ksize=(1,1,1,3), strides=(1,1,1,3), padding=\"VALID\"))\n",
        "with tf.device(\"/cpu:0\"): # 아직 GPU 커널이 없습니다.\n",
        "    depth_output = depth_pool(cropped_images)\n",
        "depth_output.shape"
      ],
      "metadata": {
        "id": "W4dJoMondURd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Input\", fontsize=14)\n",
        "plt.imshow(cropped_images[0])  # 첫 번째 이미지 그리기\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Output\", fontsize=14)\n",
        "plot_image(depth_output[0, ..., 0])  # 첫 번째 이미지 출력 그리기\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_WafyZqsdxMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 풀링\n",
        "avg_pool = keras.layers.AvgPool2D(pool_size=2)\n",
        "output_avg = avg_pool(cropped_images)"
      ],
      "metadata": {
        "id": "jrOt-674dyyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[2, 1])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[0])  # 첫 번째 이미지 그리기\n",
        "ax1.axis(\"off\")\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output_avg[0])  # 첫 번째 이미지 출력 그리기\n",
        "ax2.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xFvwXlD7eFhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN으로 패션 MNIST 문제 풀기"
      ],
      "metadata": {
        "id": "nvf-Op5mf6_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full),(X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "470Xemndf8--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - X_mean) / X_std\n",
        "X_valid = (X_valid - X_mean) / X_std\n",
        "X_test = (X_test - X_mean) / X_std"
      ],
      "metadata": {
        "id": "wCjtYr3fgPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "DmnbELDrghDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "id": "G3Au6JJpgdd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "                        kernel_size=3, activation='relu',padding='SAME')\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28,28,1]),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=128),\n",
        "    DefaultConv2D(filters=128),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=256),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(units=64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(units=10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "jqtRNV4gglGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid,y_valid))\n",
        "score = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:10]\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "id": "C_CSv23Aievl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet - 34"
      ],
      "metadata": {
        "id": "dotx_R1Ci8mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
        "                        padding=\"SAME\", use_bias=False)\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "                DefaultConv2D(filters, strides=strides),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                self.activation,\n",
        "                DefaultConv2D(filters),\n",
        "                keras.layers.BatchNormalization()]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConv2D(filters, kernel_size=1,strides=strides),\n",
        "                keras.layers.BatchNormalization()\n",
        "            ]\n",
        "\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z= inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "metadata": {
        "id": "jHKWmgyUi_aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(DefaultConv2D(64, kernel_size=7, strides=2,\n",
        "                        input_shape=[224,224,3]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "prev_filters = 64\n",
        "\n",
        "for filters in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "RsXHUn8inzzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Hbs-vEVlopA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 훈련된 모델 사용하기"
      ],
      "metadata": {
        "id": "72gp9WlFo9DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")"
      ],
      "metadata": {
        "id": "mJgHM-3to_WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_resized = tf.image.resize(images,[224,224])\n",
        "plt.imshow(images_resized[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mI2bNmT9pGMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_resized = tf.image.resize_with_pad(images, 224,224,antialias=True)\n",
        "plt.imshow(images_resized[0])"
      ],
      "metadata": {
        "id": "K1s_Jw02pQcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_resized = tf.image.resize_with_crop_or_pad(images, 224,224)\n",
        "plt.imshow(images_resized[0])"
      ],
      "metadata": {
        "id": "jLmlUfKNpfiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "china_box = [0,0.03,1,0.68]\n",
        "flower_box = [0.19,0.26,0.86,0.7]\n",
        "images_resized = tf.image.crop_and_resize(images, [china_box, flower_box], [0,1],[224,224])\n",
        "plt.imshow(images_resized[0])\n",
        "plt.show()\n",
        "plt.imshow(images_resized[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wV8GCMEEpp1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)\n",
        "Y_proba = model.predict(inputs)"
      ],
      "metadata": {
        "id": "aBbOC7SiqUuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
        "for image_index in range(len(images)):\n",
        "    print(\"Image #{}\".format(image_index))\n",
        "    for class_id, name, y_proba in top_K[image_index]:\n",
        "        print(\"  {} - {:12s} {:.2f}%\".format(class_id, name, y_proba * 100))\n",
        "    print()"
      ],
      "metadata": {
        "id": "OC3BeaFIqvO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이 학습을 위한 사전 훈련된 모델"
      ],
      "metadata": {
        "id": "arJjZK-yrQCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "411wi_WsrSHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info.splits"
      ],
      "metadata": {
        "id": "jAQV3i7grcgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info.splits['train']"
      ],
      "metadata": {
        "id": "Z5eAZNGs9xTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features['label'].names\n",
        "class_names"
      ],
      "metadata": {
        "id": "NySnGQ6n9zVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = info.features['label'].num_classes"
      ],
      "metadata": {
        "id": "JmcgYlyK92oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = info.splits['train'].num_examples\n",
        "dataset_size"
      ],
      "metadata": {
        "id": "_yqYc8nw96Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=['train[:10%]',\"train[10%:25]\",\"train[25%:]\"],\n",
        "    as_supervised=True\n",
        ")"
      ],
      "metadata": {
        "id": "fN5eE4yw99Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "index = 0\n",
        "for image, label in train_set_raw.take(9):\n",
        "    index += 1\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Class: {}'.format(class_names[label]))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "53GV59pq-S7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    resized_image = tf.image.resize(image,[224,224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image, label"
      ],
      "metadata": {
        "id": "PAF0adrd_S78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def central_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0],shape[1]])\n",
        "    top_crop = (shape[0] - min_dim) // 4\n",
        "    bottom_crop = shape[0] - top_crop\n",
        "    left_crop = (shape[1] - min_dim) //4\n",
        "    right_crop = shape[1] - left_crop\n",
        "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
        "\n",
        "def random_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
        "    return tf.image.random_crop(image, [min_dim, min_dim,3])\n",
        "\n",
        "def preprocess(image, label, randomize=False):\n",
        "    if randomize:\n",
        "        cropped_image = random_crop(image)\n",
        "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
        "    else:\n",
        "        cropped_image = central_crop(image)\n",
        "    resized_image = tf.image.resize(cropped_image, [224,224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image, label\n",
        "\n",
        "batch_size = 32\n",
        "train_set = train_set_raw.shuffle(1000).repeat()\n",
        "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
        "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
        "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "QXMLW_2v_ftE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for X_batch, y_batch in train_set.take(1):\n",
        "\n",
        "    for index in range(9):\n",
        "        plt.subplot(3,3,index+1)\n",
        "        plt.imshow(X_batch[index] / 2 + 0.5)\n",
        "        plt.title(\"Class : {}\".format(class_names[y_batch[index]]))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I1asq7gLBADt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for X_batch, y_batch in test_set.take(1):\n",
        "    for index in range(9):\n",
        "        plt.subplot(3,3,index+1)\n",
        "        plt.imshow(X_batch[index] / 2 + 0.5)\n",
        "        plt.title('Class : {}'.format(class_names[y_batch[index]]))\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8PxqZ-I0BRi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.xception.Xception(weights='imagenet',\n",
        "                                                  include_top=False)\n",
        "\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation='softmax')(avg)\n",
        "model = keras.models.Model(inputs=base_model.input,outputs=output)"
      ],
      "metadata": {
        "id": "JdZ_hixXB26z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, layer in enumerate(base_model.layers):\n",
        "    print(index,layer.name)"
      ],
      "metadata": {
        "id": "A9I0yGpnDu9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch = int(0.75*dataset_size / batch_size),\n",
        "                    validation_data=valid_set,\n",
        "                    validation_steps=int(0.15*dataset_size / batch_size),\n",
        "                    epochs=5)"
      ],
      "metadata": {
        "id": "irG0KOM8D1_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
        "                                 nesterov=True, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
        "                    validation_data=valid_set,\n",
        "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
        "                    epochs=40)"
      ],
      "metadata": {
        "id": "X4g68Q-FEm7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iyCljKtyE355"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분류와 위치 추정"
      ],
      "metadata": {
        "id": "JVvQrwD7E39o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.xception.Xception(weights='imagenet',\n",
        "                                                  include_top=False)\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "class_output = keras.layers.Dense(n_classes, activation='softmax')(avg)\n",
        "loc_output = keras.layers.Dense(4)(avg)\n",
        "model = keras.models.Model(inputs=base_model.input,\n",
        "                           outputs=[class_output, loc_output])\n",
        "model.compile(loss=['sparse_categorical_crossentropy','mse'],\n",
        "              loss_weights=[0.8,0.2],\n",
        "              optimizer =optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iylhWaaQE5G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_random_bounding_boxes(images, labels):\n",
        "    fake_bboxes = tf.random.uniform([tf.shape(image)[0],4])\n",
        "    return images, (labels, fake_bboxes)\n",
        "\n",
        "fake_train_set = train_set.take(5).repeat(2).map(add_random_bounding_boxes)"
      ],
      "metadata": {
        "id": "DDpFFpxnICq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(fake_train_set, steps_per_epoch=5, epochs=2)"
      ],
      "metadata": {
        "id": "1S3r-OmBISuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mAP(Mean Average Precision)"
      ],
      "metadata": {
        "id": "3PGhcpGYIZUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전치 합성곱"
      ],
      "metadata": {
        "id": "9uZUpMAFIiML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "X = images_resized.numpy()\n",
        "\n",
        "conv_transpose = keras.layers.Conv2DTranspose(filters=5, kernel_size=3, strides=2, padding='VALID')\n",
        "output = conv_transpose(X)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "wu09TjHtIjK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "oIWH8zzkK48O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[0,...,:6].shape"
      ],
      "metadata": {
        "id": "2Jh3DiGRKjd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized(X):\n",
        "    return (X - tf.reduce_min(X)) / (tf.reduce_max(X) - tf.reduce_min(X))\n",
        "\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[1,2])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0,0])\n",
        "ax1.set_title('Input',fontsize=14)\n",
        "ax1.imshow(X[0])\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2 = fig.add_subplot(gs[0,1])\n",
        "ax2.set_title('Output',fontsize=14)\n",
        "ax2.imshow(normalized(output[0,...,:3]), interpolation='bicubic')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SF6wOvlzIxHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale_images(images, stride, kernel_size):\n",
        "    batch_size, height, width, channels = images.shape\n",
        "    upscaled = np.zeros((batch_size,\n",
        "                         (height - 1) * stride + 2 * kernel_size -1,\n",
        "                         (width - 1) * stride + 2 * kernel_size -1,\n",
        "                         channels))\n",
        "    upscaled[:,\n",
        "             kernel_size - 1:(height - 1)*stride + kernel_size:stride,\n",
        "             kernel_size - 1:(width - 1)*stride + kernel_size:stride,\n",
        "             :] = images\n",
        "    \n",
        "    return upscaled"
      ],
      "metadata": {
        "id": "PWkkK2jnKcCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upscaled = upscale_images(X, stride=2, kernel_size=3)\n",
        "weights, biases = conv_transpose.weights\n",
        "reversed_filters = np.flip(weights.numpy(), axis=[0,1])\n",
        "reversed_filters = np.transpose(reversed_filters,[0,1,3,2])\n",
        "manual_output = tf.nn.conv2d(upscaled, reversed_filters, strides=1, padding=\"VALID\")"
      ],
      "metadata": {
        "id": "A-kny1UANOuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(X):\n",
        "    return (X - tf.reduce_min(X)) / (tf.reduce_max(X) - tf.reduce_min(X))\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=3, width_ratios=[1, 2, 2])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(X[0])  # 첫 번째 이미지 그리기\n",
        "ax1.axis(\"off\")\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Upscaled\", fontsize=14)\n",
        "ax2.imshow(upscaled[0], interpolation=\"bicubic\")\n",
        "ax2.axis(\"off\")\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "ax3.set_title(\"Output\", fontsize=14)\n",
        "ax3.imshow(normalize(manual_output[0, ..., :3]), interpolation=\"bicubic\")  # 첫 번째 이미지 출력 그리기\n",
        "ax3.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TxRJ0OkrNszI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(output, manual_output.numpy(), atol=1e-7)"
      ],
      "metadata": {
        "id": "HuWd02AqN5zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. MNIST 에서 높은 정확도를 내는 CNN 만들기"
      ],
      "metadata": {
        "id": "Rplr9XaqOUYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "-Lpc-daKOXlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "bU-nV5ppO_Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "id": "VP9gUi86OgwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "yzkgJnvlPBzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\",activation='relu'),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding='same',activation='relu'),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128,activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "8xJHCcyVPCbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gGq_yDW7QFVA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}