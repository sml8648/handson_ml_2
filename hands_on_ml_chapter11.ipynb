{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hands-on-ml chapter11.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPlkcQhYrocDcpesvEL2RpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/handson_ml_2/blob/main/hands_on_ml_chapter11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-obPHa78y8KB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "eiGL63_IzlCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "_gA9qbP9znGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "metadata": {
        "id": "WjOVJQac0k-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"image\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "viHY0S6Y1Ev0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_fig(fig_id, tight_layout=True, fig_extension='png', resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "Nbf5K-0o1aQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tha Vanishing/Exploding Gradients Problems"
      ],
      "metadata": {
        "id": "IBO4LXtC3QYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logit(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "OzmWFdq13ojz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.linspace(-5,5,200)\n",
        "\n",
        "plt.plot([-5,5],[0,0], 'k--')\n",
        "plt.plot([-5,5],[1,1], 'k--')\n",
        "plt.plot([0,0],[-0.2,1.2],'k-')\n",
        "plt.plot([-5,5],[-3/4, 7/4], 'g--')\n",
        "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
        "\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "\n",
        "plt.annotate('Saturating',xytext=(3.5,0.7), xy=(5,1), arrowprops=props, fontsize=14, ha='center')\n",
        "plt.annotate('Saturating',xytext=(-3.5,0.3), xy=(-5,0), arrowprops=props, fontsize=14, ha='center')\n",
        "plt.annotate('Linear', xytext=(2,0.2), xy=(0,0.5),arrowprops=props, fontsize=14, ha='center')\n",
        "plt.grid(True)\n",
        "plt.title('Sigmoid activation function', fontsize=14)\n",
        "plt.axis([-5,5,-0.2,1.2])\n",
        "\n",
        "save_fig('sigmoid_saturation_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rVuufOcZ3uAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xavier initialization and He initialization"
      ],
      "metadata": {
        "id": "1ss6BaQB5ebl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
      ],
      "metadata": {
        "id": "NXJ7yv_P5iWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')"
      ],
      "metadata": {
        "id": "A4xTRuEL5nit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
        "                                         distribution='uniform')\n",
        "keras.layers.Dense(10, activation='relu', kernel_initializer=init)"
      ],
      "metadata": {
        "id": "o6a6VKn155mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nonsaturating Activation Functions"
      ],
      "metadata": {
        "id": "dwcddjP2670Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LeakyReLu\n",
        "def leaky_relu(z, alpha=0.01):\n",
        "    return np.maximum(alpha*z, z)"
      ],
      "metadata": {
        "id": "Zfj13iAy69xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(z, leaky_relu(z, 0.05),\"b-\",linewidth=2)\n",
        "plt.plot([-5,5],[0,0],'k-')\n",
        "plt.plot([0,0],[-0.5,4.2], 'k-')\n",
        "plt.grid(True)\n",
        "\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('Leak',xytext=(-3.5, 0.5), xy=(-5,-0.2),arrowprops=props, fontsize=14, ha='center')\n",
        "plt.title('Leaky ReLu activation function', fontsize=14)\n",
        "plt.axis([-5,5,-0.5,4.2])\n",
        "\n",
        "save_fig('leaky_relu_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n7hCnbCq7Hwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions in keras activation\n",
        "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
      ],
      "metadata": {
        "id": "FKXYeUTE7eEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[m for m in dir(keras.layers) if 'relu' in m.lower()]"
      ],
      "metadata": {
        "id": "Q1YrLm0e8F3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST with LeakyReLU\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "Mpguecb_8KGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "metadata": {
        "id": "ksNZ395M8ZO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "AgeRsfJc8vnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-T0wK90m9-Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QycjHRA69k4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "6zNeVXtD9x35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PReLu\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "iFjQVl7h-LjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "bEc7MeeB-YQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "eZRj6sEl-aYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SELU"
      ],
      "metadata": {
        "id": "et7eZezT_xye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def elu(z, alpha=1):\n",
        "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
      ],
      "metadata": {
        "id": "3_AQiJOhAUTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import erfc\n",
        "\n",
        "# 논문에 나와있는 식이라고 하네\n",
        "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
      ],
      "metadata": {
        "id": "38MtXmfB_yXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "    return scale * elu(z, alpha)"
      ],
      "metadata": {
        "id": "7TM0EPWMAIUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5,5],[0,0], 'k-')\n",
        "plt.plot([-5,5],[-1.758,-1.758],'k--')\n",
        "plt.plot([0,0],[-2.2, 3.2],'k-')\n",
        "plt.grid(True)\n",
        "plt.title(\"SELU activation function\", fontsize=14)\n",
        "plt.axis([-5,5,-2.2, 3.2])\n",
        "\n",
        "save_fig('selu_plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "60JG-dGhARjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selu를 1000층이 있는 신경망에 학습시켰을때의 시뮬레이션\n",
        "\n",
        "Z = np.random.normal(size=(500,100))\n",
        "for layer in range(1000):\n",
        "    W = np.random.normal(size=(100,100), scale=np.sqrt(1/100))\n",
        "    Z = selu(np.dot(Z,W))\n",
        "    means = np.mean(Z, axis=0).mean()\n",
        "    stds = np.std(Z, axis=0).mean()\n",
        "    if layer % 100 == 0:\n",
        "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
      ],
      "metadata": {
        "id": "hS245HkCBPMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SELU in keras\n",
        "keras.layers.Dense(10, activation='selu',\n",
        "                   kernel_initializer=\"lecun_normal\")"
      ],
      "metadata": {
        "id": "NtbJQ8NNBq9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
        "                             kernel_initializer=\"lecun_normal\"))\n",
        "\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation='selu',\n",
        "                                 kernel_initializer=\"lecun_normal\"))\n",
        "    \n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "rSg-E7iGDUVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-3xDlhnjEPA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "metadata": {
        "id": "c0LRimYQEac2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled,y_valid))"
      ],
      "metadata": {
        "id": "cRotmgDgExWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relu로 해당 네트워크 테스트\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\",\n",
        "                             kernel_initializer=\"he_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation='relu',\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "8U-jkzB7E40n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8xJySmdvFJir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled,y_valid))"
      ],
      "metadata": {
        "id": "-pHF7PAqFMdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch normalization"
      ],
      "metadata": {
        "id": "m9sLM4qoFODK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "OMLKDjxIFPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "tOEW95jUHubi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bn1 = model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ],
      "metadata": {
        "id": "RCYfdrXoHwVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "52dtKJgeH5En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "2GRO7EckIfXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch norm을 첫번째 dense layer 이전에 적용하는 기법도 잘동작한다.\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(100, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "lgoimHSkIlrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DibG_DQwJgGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "E9HV_rUwJqa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Clipping"
      ],
      "metadata": {
        "id": "7obGUNgIJzqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
        "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
      ],
      "metadata": {
        "id": "rCPhVO5UJ0mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reusing Pretrained Layers"
      ],
      "metadata": {
        "id": "Zb3L6QmkKHe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ],
      "metadata": {
        "id": "W40A2SkpKJrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.Sequential()\n",
        "model_A.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "for n_hidden in (300,100,50,50,50):\n",
        "    model_A.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
        "model_A.add(keras.layers.Dense(8, activation='softmax'))"
      ],
      "metadata": {
        "id": "di0uAT_bLlun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jvyNSbfIL88M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "id": "tH9aLY1yMK83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save('my_model_A.h5')"
      ],
      "metadata": {
        "id": "k46R6aSCMS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model B\n",
        "model_B = keras.models.Sequential()\n",
        "model_B.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "for n_hidden in (300,100,50,50,50):\n",
        "    model_B.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
        "model_B.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "qeFjh_ODMsxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.compile(loss='binary_crossentropy',\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lKMRl-OmNZKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "i_T-2JkSNiyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.summary()"
      ],
      "metadata": {
        "id": "0R0H6nXvNuQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이렇게 하면 2개의 모델이 한번에 훈련이 됨으로 copy를 사용해야함\n",
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "WIppdEFuNydZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A.summary()"
      ],
      "metadata": {
        "id": "nA4Bw-GAQvbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())\n",
        "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "FKtlnTfxOC_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_B_on_A.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,validation_data=(X_valid_B,y_valid_B))\n",
        "# 사전 학습된 모델을 써도 정확도가 나쁘지 않게 나온다"
      ],
      "metadata": {
        "id": "3M56yyrjQ1Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_B_on_A.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "udojFG3KRag0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "id": "Cy-ypE7tR41Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "id": "e2Q2nbITSD5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차율이 얼마나 증가했는지 확인하는 식\n",
        "(100 - 98.9) / (100 - 99.6)"
      ],
      "metadata": {
        "id": "L3TFzOonSHwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fater Optimizer"
      ],
      "metadata": {
        "id": "Tmemz0DRSSot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Momentum\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "# Nesterov\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "# AdaGrad\n",
        "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "# RMSProp\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "# Adam\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "# Adamax\n",
        "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "# Nadam\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "_rwfT7QHSZUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning rate scheduling"
      ],
      "metadata": {
        "id": "5ZH-WTFcyl7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
      ],
      "metadata": {
        "id": "h7s9KxjByn4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300,activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(100,activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9OpBseuJy3Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "gFAVUrn07pdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "learning_rate = 0.01\n",
        "decay = 1e-4\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
        "epochs = np.arange(n_epochs)\n",
        "lrs = learning_rate / (1 + decay*epochs*n_steps_per_epoch)\n",
        "\n",
        "plt.plot(epochs, lrs, \"o-\")\n",
        "plt.axis([0,n_epochs - 1,0, 0.01])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title(\"Power Scheduling\",fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h8QSgkkR70Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exponential based scheduling"
      ],
      "metadata": {
        "id": "1t4QVYXI9_sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay_fn(epoch):\n",
        "    return 0.01 * 0.1 ** (epoch / 20)"
      ],
      "metadata": {
        "id": "mrjbyPfT-BWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매 epoch 마다 변수가 들어가나 보다\n",
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1 ** (epoch/s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
      ],
      "metadata": {
        "id": "u7p-j8nz-LAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(100, activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "n_epochs = 25"
      ],
      "metadata": {
        "id": "xolaW_U7-bEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data = (X_valid_scaled,y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "2u8eu44y-5Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history['lr'],'o-')\n",
        "plt.axis([0,n_epochs - 1, 0,0.011])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling\",fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s1tsFDJ3_Mvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에포크말고 반복마다 학습률을 업데이트하려면 새로운 콜백 클래스를 작성해야한다.\n",
        "def exponential_decay_fn(epoch, lr):\n",
        "    return lr*0.1**(1/20)"
      ],
      "metadata": {
        "id": "tkyg72wH_1N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialDecay(keras.callbacks.Callback):\n",
        "    def __init__(self, s=40000):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # 에포크 마다 배치 변수가 재설정 된다?\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        K.set_value(self.model.optimizer.lr, lr*0.1**(self.s))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, activation='relu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "lr0 = 0.01\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "n_epochs = 25\n",
        "\n",
        "s = 20 * len(X_train) // 32\n",
        "exp_decay = ExponentialDecay(s)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled,y_valid),\n",
        "                    callbacks=[exp_decay])"
      ],
      "metadata": {
        "id": "2sVUW_4dBBIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = n_epochs * len(X_train) // 32\n",
        "steps = np.arange(n_steps)\n",
        "lrs = lr0 * 0.1 ** (steps / s)"
      ],
      "metadata": {
        "id": "zqHownSsDAkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
        "plt.axis([0,n_steps - 1,0, lr0 * 1.1])\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MmpOGF_AEQaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Cycle scheduling"
      ],
      "metadata": {
        "id": "uliQXS6vEkc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
        "        self.losses.append(logs['loss'])\n",
        "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
        "\n",
        "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
        "    init_weights = model.get_weights()\n",
        "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
        "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
        "    init_lr = K.get_value(model.optimizer.lr)\n",
        "    K.set_value(model.optimizer.lr, min_rate)\n",
        "    exp_lr = ExponentialLearningRate(factor)\n",
        "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
        "                       callbacks=[exp_lr])\n",
        "    K.set_value(model.optimizer.lr, init_lr)\n",
        "    model.set_weights(init_weights)\n",
        "    return exp_lr.rates, exp_lr.losses\n",
        "\n",
        "def plot_lr_vs_loss(rates, losses):\n",
        "    plt.plot(rates, losses)\n",
        "    plt.gca().set_xscale('log')\n",
        "    plt.hlines(min(losses),min(rates),max(rates))\n",
        "    plt.axis([min(rates),max(rates),min(losses),(losses[0] + min(losses)) /2])\n",
        "    plt.xlabel(\"Learning rate\")\n",
        "    plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "DxT7fKBQEmhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28,28)),\n",
        "    keras.layers.Dense(300, activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(100, activation='selu',kernel_initializer='lecun_normal'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MoVbP-irFZNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)"
      ],
      "metadata": {
        "id": "AavBpcbNKGZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneCycleScheduler(keras.callbacks.Callback):\n",
        "    def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                 last_iterations=None, last_rate=None):\n",
        "        self.iterations = iterations\n",
        "        self.max_rate = max_rate\n",
        "        self.start_rate = start_rate or max_rate / 10\n",
        "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "        self.last_rate = last_rate or self.start_rate / 1000\n",
        "        self.iteration = 0\n",
        "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                / (iter2 - iter1) + rate1)\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        if self.iteration < self.half_iteration:\n",
        "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "        elif self.iteration < 2 * self.half_iteration:\n",
        "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                     self.max_rate, self.start_rate)\n",
        "        else:\n",
        "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                     self.start_rate, self.last_rate)\n",
        "        self.iteration += 1\n",
        "        K.set_value(self.model.optimizer.lr, rate)"
      ],
      "metadata": {
        "id": "3MbT0lVbKRCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25\n",
        "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ],
      "metadata": {
        "id": "LdbsO2YHLLsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L1 and L2 Regularization"
      ],
      "metadata": {
        "id": "Ty7QgB0FLRZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation='elu',\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))"
      ],
      "metadata": {
        "id": "j_6VUivWLVH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300,activation='elu',\n",
        "                       kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(100,activation='elu',\n",
        "                       kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(10, activation='softmax',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "gZYGnX-bLlv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 리팩토링\n",
        "from functools import partial\n",
        "\n",
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation='elu',\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "lc3QruQyPGwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout"
      ],
      "metadata": {
        "id": "LciwRb-eQte-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation='elu',kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation='elu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "tSkqb98HQuVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alpha Dropout"
      ],
      "metadata": {
        "id": "qtT0xewdRc16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation='selu', kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation='selu', kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n",
        "n_epochs = 20\n",
        "history = model.fit(X_train_scaled,y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "Ofep_KUrRevG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "akXLT0j1SdWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "cKULXWvCS3jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "rdBxTX_zTBa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MC Dropout"
      ],
      "metadata": {
        "id": "4VnK86teTNKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True)\n",
        "                    for sample in range(100)])"
      ],
      "metadata": {
        "id": "Lf4iIGcMTOPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_probas.shape"
      ],
      "metadata": {
        "id": "9Jwgw8lmWYAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = y_probas.mean(axis=0)"
      ],
      "metadata": {
        "id": "ESjvfxrjWYqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_std = y_probas.std(axis=0)"
      ],
      "metadata": {
        "id": "UixndN1eW3B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(model.predict(X_test_scaled[:1]),2)"
      ],
      "metadata": {
        "id": "xCSBa2AGW30r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_probas[:,:1],2).shape"
      ],
      "metadata": {
        "id": "zWmKpEOuXCDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_proba[:1],2)"
      ],
      "metadata": {
        "id": "rhljzDdyXGsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_std = y_probas.std(axis=0)\n",
        "np.round(y_std[:1],2)"
      ],
      "metadata": {
        "id": "6fXNh0EUXSVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_proba, axis=1)"
      ],
      "metadata": {
        "id": "IT7xRoS5XWBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "qC2rALQxXY9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "    def call(self,inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "    \n",
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self,inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "T0rxCMqQXeK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ],
      "metadata": {
        "id": "Wt7g_SS1XyaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.summary()"
      ],
      "metadata": {
        "id": "RYayhRR9YFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ykYU2HhCYNED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.set_weights(model.get_weights())"
      ],
      "metadata": {
        "id": "21aiSfvjYd1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)],axis=0),2)"
      ],
      "metadata": {
        "id": "NHnWmDXQYgup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max Norm"
      ],
      "metadata": {
        "id": "H-Eib0c3Ys1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal',\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ],
      "metadata": {
        "id": "0t5o_XkxYttx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaxNormDense = partial(keras.layers.Dense,\n",
        "                       activation='selu',kernel_initializer='lecun_normal',\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    MaxNormDense(300),\n",
        "    MaxNormDense(100),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "VjIk7jMvY6q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "wPHuO3vcZ0m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 100개의 뉴런을 가진 은닉층 20개로 심층 신경망을 만들어보자\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "# flatten으로 3차원 데이터도 펼칠수가 있구나\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation='elu',\n",
        "                                 kernel_initializer=\"he_normal\"))"
      ],
      "metadata": {
        "id": "VycbMR4uZ1rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "6PudSVoYaTb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FJM-fgjtcdfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "WSWeBZ4ycsJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]"
      ],
      "metadata": {
        "id": "k0Krwb1pc0Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('my_cifar10_model.h5',save_best_only=True)\n",
        "# run index가 자동으로 증가하는건가?\n",
        "run_index = 1\n",
        "run_logdir = os.path.join(os.curdir, 'my_cifar10_logs',\"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ],
      "metadata": {
        "id": "Zn_x46PcdDsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=./my_cifar10_logs --port=6006"
      ],
      "metadata": {
        "id": "Y9pYS7BndnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "id": "pt0wBxondvv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('my_cifar10_model.h5')\n",
        "model.evaluate(X_valid, y_valid)\n",
        "# 46%의 정확도가 나왔다."
      ],
      "metadata": {
        "id": "sbEyDzPUd8js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C."
      ],
      "metadata": {
        "id": "WhOPsNJJeshY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100, kernel_initializer='he_normal'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('elu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\",save_best_only=True)\n",
        "run_index = 1\n",
        "run_logdir = os.path.join(os.curdir,\"my_cifar10_logs\",\"run_bn_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "-mD6qMvwetlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# d."
      ],
      "metadata": {
        "id": "m-S96xjziZ13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer='lecun_normal',\n",
        "                                 activation='selu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\",save_best_only=True)\n",
        "run_index = 1\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\",\"run_selu_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data = (X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "id": "9G2ctxjRiaZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('my_cifar10_selu_model.h5')\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "id": "gamPicMgoVBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E."
      ],
      "metadata": {
        "id": "6lYqTyI_ohs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer='lecun_normal',\n",
        "                                 activation='selu'))\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('my_cifar10_alpha_dropout_model.h5',save_best_only=True)\n",
        "run_index = 1\n",
        "run_logdir = os.path.join(os.curdir,'my_cifar10_logs','run_alpha_dropout_{:03d}'.format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_mean = X_train.mean(axis=0)\n",
        "X_std = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "id": "I-zrwMm_oiOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('my_cifar10_alpha_dropout_model.h5')\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "id": "fTI2wMgbqhEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "W-5wA_GGqraW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance (layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ],
      "metadata": {
        "id": "zZaVy39zrU4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
        "    Y_probas = [mc.model.predict(X) for sample in range(n_samples)]\n",
        "    return np.mean(Y_probas, axis=0)\n",
        "\n",
        "def mc_dropout_prdict_probas(mc_model, X, n_samples=10):\n",
        "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
        "    return np.argmax(Y_probas, axis=1)"
      ],
      "metadata": {
        "id": "LS2s3-Zrrj7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
        "accuracy = np.mean(y_pred == y_valid[:,0])\n",
        "accuracy"
      ],
      "metadata": {
        "id": "yZEnwu92sPyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F."
      ],
      "metadata": {
        "id": "f9ojG4X2sfzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer='lecun_normal',\n",
        "                                 activation='selu'))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "U6lYKg5ushCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)\n",
        "plt.axis([min(rates),max(rates),min(losses),(losses[0] + min(losses)) / 1.4])"
      ],
      "metadata": {
        "id": "hzA0Wz1dtoMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer='lecun_normal',\n",
        "                                 activation='selu'))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimzer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IdL1n65suted"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 15\n",
        "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ],
      "metadata": {
        "id": "krkHB7mhvWO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "huIESp9bvtBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}