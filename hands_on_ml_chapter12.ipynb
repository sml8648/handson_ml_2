{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hands-on-ml chapter12.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBWJxmLpi5Ezj7pkuf7Pj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/handson_ml_2/blob/main/hands_on_ml_chapter12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrSRKctO114x"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes',labelsize=14)\n",
        "mpl.rc('xtick',labelsize=12)\n",
        "mpl.rc('ytick',labelsize=12)\n",
        "\n",
        "PROJECT_ROOT_DIR = '.'\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\",CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension='png',resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + '.' + fig_extension)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "PU-DmndS2gh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor and Operation"
      ],
      "metadata": {
        "id": "4KTMhRs73fwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([[1.,2.,3.],[4.,5.,6.]])"
      ],
      "metadata": {
        "id": "YEGfDJyX3lN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(42)"
      ],
      "metadata": {
        "id": "jiK5vtQG3wTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.constant([[1.,2.,3.],[4.,5.,6]])\n",
        "t"
      ],
      "metadata": {
        "id": "GWF0Mmu83zJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape"
      ],
      "metadata": {
        "id": "XZNHtkSO34s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.dtype"
      ],
      "metadata": {
        "id": "OSVZEU-R35zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "FnVgEN5Y37_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t[:,1:]"
      ],
      "metadata": {
        "id": "7BOrLEM338tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keras.backend"
      ],
      "metadata": {
        "id": "C7ExXM2U45ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "k = keras.backend\n",
        "k.square(k.transpose(t)) + 10"
      ],
      "metadata": {
        "id": "J4LR4NbR46mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy convert"
      ],
      "metadata": {
        "id": "wlz35byE5p_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([2.,4.,5.])\n",
        "tf.constant(a)"
      ],
      "metadata": {
        "id": "UwPNRIsW5rMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.numpy()"
      ],
      "metadata": {
        "id": "tGUFzf3I6VBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(t)"
      ],
      "metadata": {
        "id": "s59X5ptt6YZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.square(a)"
      ],
      "metadata": {
        "id": "Cn9XuaZJ6Z_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.square(t)"
      ],
      "metadata": {
        "id": "zr2JKbPr6nso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# type conversion"
      ],
      "metadata": {
        "id": "TQNSFxZA6qB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "jg-9Qpja6reT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "fNeiTCNb6zus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "tf.constant(2.0) + tf.cast(t2, tf.float32)"
      ],
      "metadata": {
        "id": "arYzCxDh7Bsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# String"
      ],
      "metadata": {
        "id": "GC6B2R8n7KPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(b\"hello world\")"
      ],
      "metadata": {
        "id": "72uoh9g-7K21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(\"cafe\")"
      ],
      "metadata": {
        "id": "Vvg3Oaa37XHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = tf.constant([ord(c) for c in \"cafe\"])\n",
        "u"
      ],
      "metadata": {
        "id": "_n5aE0Kj7cE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.strings.unicode_encode(u,\"UTF-8\")\n",
        "tf.strings.length(b, unit=\"UTF8_CHAR\")"
      ],
      "metadata": {
        "id": "cYV14yzS7mL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.unicode_decode(b, \"UTF-8\")"
      ],
      "metadata": {
        "id": "vJcEAZ7p70Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text array"
      ],
      "metadata": {
        "id": "iVepzaH88FHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = tf.constant([\"Cafe\",\"Coffee\",\"caffe\"])"
      ],
      "metadata": {
        "id": "vBWHYADJ8GBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.length(p, unit=\"UTF8_CHAR\")"
      ],
      "metadata": {
        "id": "dbQdR7Ye8M4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
        "r"
      ],
      "metadata": {
        "id": "ZIeJ7Yb28R59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(r)"
      ],
      "metadata": {
        "id": "BSF5N0zG8aqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ragged tensor"
      ],
      "metadata": {
        "id": "rZ-jh2pL8fYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(r[1])"
      ],
      "metadata": {
        "id": "wJhhCIdy8gQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(r[1:3])"
      ],
      "metadata": {
        "id": "CJU0FLTQ8rE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = tf.ragged.constant([[65,66],[],[67]])\n",
        "print(tf.concat([r,r2],axis=0))"
      ],
      "metadata": {
        "id": "sLmRHisO8smK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r3 = tf.ragged.constant([[66,69,70],[71],[],[72,73]])"
      ],
      "metadata": {
        "id": "s5uw0dok8_sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sparse tensor"
      ],
      "metadata": {
        "id": "nZLQduUB9X7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = tf.SparseTensor(indices=[[0,1],[1,0],[2,3]],\n",
        "                    values=[1.,2.,3.],\n",
        "                    dense_shape=[3,4])"
      ],
      "metadata": {
        "id": "GZcBjaG_9ZbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s)"
      ],
      "metadata": {
        "id": "RTlBNLc99nN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sparse.to_dense(s)"
      ],
      "metadata": {
        "id": "W5veuD1f9njt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2 = s * 2.0"
      ],
      "metadata": {
        "id": "J0BmjuHI9tug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sparse.to_dense(s2)"
      ],
      "metadata": {
        "id": "AOj23OsXAhS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    s3 = s + 1.\n",
        "except TypeError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "9ZWHsxnaAAtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s4 = tf.constant([[10.,20.],[30.,40.],[50.,60.],[70.,80.]])\n",
        "tf.sparse.sparse_dense_matmul(s, s4)"
      ],
      "metadata": {
        "id": "LRxEC_3gAGs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s5 = tf.SparseTensor(indices=[[0,2],[0,1]],\n",
        "                     values=[1.,2.],\n",
        "                     dense_shape=[3,4])\n",
        "print(s5)"
      ],
      "metadata": {
        "id": "RtQcXiW3ATvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tf.sparse.to_dense(s5)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "8a8ZTu4jCZ_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s6 = tf.sparse.reorder(s5)\n",
        "tf.sparse.to_dense(s6)"
      ],
      "metadata": {
        "id": "QK3NkmKjCiKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set"
      ],
      "metadata": {
        "id": "y-LFbLnGCosC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set1 = tf.constant([[2,3,5,7],[7,9,0,0]])\n",
        "set2 = tf.constant([[4,5,6],[9,10,0]])\n",
        "tf.sparse.to_dense(tf.sets.union(set1, set2))"
      ],
      "metadata": {
        "id": "lLdUOIecCpDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
      ],
      "metadata": {
        "id": "CsNbtTpCC8nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
      ],
      "metadata": {
        "id": "I38D_xgTDCCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 변수"
      ],
      "metadata": {
        "id": "6mr4aHKtDMvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.Variable([[1.,2.,3.],[4.,5.,6.]])"
      ],
      "metadata": {
        "id": "fvoRhcHJDNbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v.assign(2*v)"
      ],
      "metadata": {
        "id": "pfL3FQBrDTck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v[0,1].assign(42)"
      ],
      "metadata": {
        "id": "JCZMaDGiDUjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    v[1] = [7.,8.,9.]\n",
        "except TypeError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "sVXtmyqRDXUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v.scatter_nd_update(indices=[[0,0],[1,2]],\n",
        "                    updates=[100.,200.])"
      ],
      "metadata": {
        "id": "w2WTmP5rDe0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_delta = tf.IndexedSlices(values=[[1.,2.,3.],[4.,5.,6.]],\n",
        "                                indices=[1,0])\n",
        "v.scatter_update(sparse_delta)"
      ],
      "metadata": {
        "id": "75vE7qIoDriU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tensor array"
      ],
      "metadata": {
        "id": "wn-krNt_D7Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
        "array = array.write(0, tf.constant([1.,2.]))\n",
        "array = array.write(1, tf.constant([3.,10.]))\n",
        "array = array.write(2, tf.constant([5.,7.]))"
      ],
      "metadata": {
        "id": "muykZ_w1D8P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array.stack()"
      ],
      "metadata": {
        "id": "jVQi1lcrEKtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
        "mean"
      ],
      "metadata": {
        "id": "WvgUuTO6EQsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variance"
      ],
      "metadata": {
        "id": "FlZvC3pbEXlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# user define loss function"
      ],
      "metadata": {
        "id": "bB9akxCNEeJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1,1), random_state=42)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)"
      ],
      "metadata": {
        "id": "0mHgwPoqEfcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# 다 전부 따로 스케일링을 하네 나눈다음에\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.fit_transform(X_valid)\n",
        "X_test_scaled = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "LjUOWaLXFDm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "metadata": {
        "id": "1DJ1WzDDFdqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,3.5))\n",
        "z = np.linspace(-4, 4, 200)\n",
        "plt.plot(z, huber_fn(0,z),\"b-\",linewidth=2,label='huber($z$)')\n",
        "plt.plot(z, z**2 / 2, 'b:',linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
        "plt.plot([-1,-1],[0,huber_fn(0.,-1.)],\"r--\")\n",
        "plt.plot([1,1],[0,huber_fn(0.,1.)],\"r--\")\n",
        "plt.gca().axhline(y=0,color='k')\n",
        "plt.gca().axvline(x=0,color='k')\n",
        "plt.axis([-4,4,0,4])\n",
        "plt.grid(True)\n",
        "plt.xlabel('$z$')\n",
        "plt.legend(fontsize=14)\n",
        "plt.title(\"Huber loss\",fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Entk2jC3FvZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='selu',kernel_initializer='lecun_normal',\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "ar3I_f0HGRgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "_vfmX2nDG9uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=20,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "hTULE1GOHfFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and load user defined model"
      ],
      "metadata": {
        "id": "wVFSo913H57U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model_with_a_custom_loss.h5')"
      ],
      "metadata": {
        "id": "oWkOLcHGIAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('my_model_with_a_custom_loss.h5',\n",
        "                                custom_objects={\"huber_fn\":huber_fn})"
      ],
      "metadata": {
        "id": "_HUVcXOXIEjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "MsqRNOaRIOhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true,y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold**2/2\n",
        "        return tf.where(is_small_error,)\n",
        "    return huber_fn"
      ],
      "metadata": {
        "id": "E_yt8XOzIYIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=create_huber(2.0),optimizer=\"nadam\",metrics=['mae'])"
      ],
      "metadata": {
        "id": "bEhpaRaOQ8i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled_casted = X_train_scaled.astype('float32')\n",
        "y_train_casted = y_train.astype('float32')\n",
        "X_valid_scaled_casted = X_valid_scaled.astype('float32')\n",
        "y_valid_casted = y_valid.astype('float32')"
      ],
      "metadata": {
        "id": "XTeirRqFR_gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "QfNfLCVJRGeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberLoss(keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2/2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\":self.threshold}"
      ],
      "metadata": {
        "id": "2_SS86yoRNE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='selu',kernel_initializer='lecun_normal',\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "llXZ3HujTZAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=HuberLoss(2.),optimizer='nadam',metrics=['mae'])"
      ],
      "metadata": {
        "id": "gceOEElxTvAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "YV-RlUEST0PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_model_with_a_custom_loss_class.h5\")"
      ],
      "metadata": {
        "id": "BKaoxn99T5ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
        "                                custom_objects={\"HuberLoss\":HuberLoss})"
      ],
      "metadata": {
        "id": "tDj8jdPrUAwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "l_ock5PnUI_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.loss.threshold"
      ],
      "metadata": {
        "id": "ugp-Og-TVtx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# other custom function"
      ],
      "metadata": {
        "id": "rmB_LlzNVw05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softplus(z):\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2./(shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_11_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01*weights))\n",
        "\n",
        "def my_positive_weights(weights):\n",
        "    return tf.where(weights < 0.,tf.zeros_like(weights),weights)"
      ],
      "metadata": {
        "id": "FWz9F3R0VzXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom metrics"
      ],
      "metadata": {
        "id": "KPOH-lc_Whki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "6gy4QFZ_Wnxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='selu',kernel_initializer='lecun_normal',\n",
        "                        input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "FVk451zpWqfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',optimizer='nadam',metrics=[create_huber(2.0)])"
      ],
      "metadata": {
        "id": "ZCyyY_b3W1I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ],
      "metadata": {
        "id": "kfbN5iMUXQfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=create_huber(2.0),optimizer=\"nadam\",metrics=[create_huber(2.0)])"
      ],
      "metadata": {
        "id": "bWGWMFHzXVgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weight = np.random.rand(len(y_train))\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
      ],
      "metadata": {
        "id": "Q3ro0hX7aPR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming metrics"
      ],
      "metadata": {
        "id": "opJ8oWAradmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom layer"
      ],
      "metadata": {
        "id": "nDGdqTD5aoEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_layer = keras.layers.Lambda(lambda x : tf.exp(x))"
      ],
      "metadata": {
        "id": "iIRHVVCTapCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_layer([-1.,0.,1.])"
      ],
      "metadata": {
        "id": "3NizP2OIa5al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "_rI9vQEGa-Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "    exponential_layer\n",
        "])\n",
        "\n",
        "# metric이 없네?? 없어도 되나?\n",
        "model.compile(loss='mse',optimizer='sgd')\n",
        "model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "EtdQlL0GbBlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "    \n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1],self.units],\n",
        "            initializer='glorot_normal')\n",
        "        self.bias = self.add_weight(\n",
        "            name='bias',shape=[self.units], initializer='zeros')\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X@self.kernel + self.bias)\n",
        "    \n",
        "    def compute_output_shape(self,batch_input_shape):\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "    \n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\":self.units,\n",
        "                \"activation\":keras.activations.serialize(self.activation)}"
      ],
      "metadata": {
        "id": "CKQiLMX8biQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "WegbEGKpcZ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    MyDense(30, activation='relu', input_shape=input_shape),\n",
        "    MyDense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "vZGStaeUdNB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',optimizer='nadam')\n",
        "model.fit(X_train_scaled,y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "rgdmzIltdT6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_model_with_a_custom_layer.h5\")"
      ],
      "metadata": {
        "id": "Sf6FzDSOdg7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
        "                          custom_objects={'MyDense':MyDense})"
      ],
      "metadata": {
        "id": "0vi_6zbpdmaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMultiLayer(keras.layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        print(\"X1.shape: \", X1.shape, \"X2.shape: \",X2.shape)\n",
        "        return X1 + X2, X1 * X2\n",
        "    \n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
        "        return [batch_input_shape1, batch_input_shape2]"
      ],
      "metadata": {
        "id": "iJblLsV8dx_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 = keras.layers.Input(shape=[2])\n",
        "inputs2 = keras.layers.Input(shape=[2])\n",
        "output1, output2 = MyMultiLayer()((inputs1, inputs2))"
      ],
      "metadata": {
        "id": "NZGUQKRLf9xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    columns_count = data.shape[-1]\n",
        "    half = columns_count // 2\n",
        "    return data[:,:half], data[:,half:]\n",
        "\n",
        "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
        "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
        "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
        "\n",
        "# Splitted data\n",
        "X_train_scaled_A.shape, X_train_scaled_B.shape"
      ],
      "metadata": {
        "id": "OS3fzfj5gTPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
      ],
      "metadata": {
        "id": "fS3pL8Fvg6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs1[0]"
      ],
      "metadata": {
        "id": "zfYBLwqrhDC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
        "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
        "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
        "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
        "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
        "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B],outputs=[output])"
      ],
      "metadata": {
        "id": "CbW02eKvhJpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',optimizer='nadam')"
      ],
      "metadata": {
        "id": "_tDtTiGriRwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
        "          validation_data=((X_valid_scaled_A, X_valid_scaled_B),y_valid))"
      ],
      "metadata": {
        "id": "JKdgNjSZjJ1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련과 테스트에서 다르게 동작하는 층\n",
        "class AddGaussianNoise(keras.layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "    \n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        else:\n",
        "            return X\n",
        "        \n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return batch_input_shape"
      ],
      "metadata": {
        "id": "_BozkFg4jT6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    AddGaussianNoise(stddev=1.0),\n",
        "    keras.layers.Dense(30, activation='selu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "odttL-uDj44x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',optimizer='nadam')\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled,y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "zdvMe3islJL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom model"
      ],
      "metadata": {
        "id": "VXHWdxKgldct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new_scaled = X_test_scaled"
      ],
      "metadata": {
        "id": "LkdUlDDSleQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z"
      ],
      "metadata": {
        "id": "istldyp2l9Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualRegressor(keras.models.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3):\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)"
      ],
      "metadata": {
        "id": "OfDVz9A6nNMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "w64gcPc7nOGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ],
      "metadata": {
        "id": "bmB77YMAnO_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_custom_model.ckpt\")"
      ],
      "metadata": {
        "id": "RgH9VpavnQCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_custom_model.ckpt\")"
      ],
      "metadata": {
        "id": "KifwCkSHnRKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "iVLjiKvqnSL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "8w2pQhZ4nY3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block1 = ResidualBlock(2, 30)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    block1, block1, block1, block1,\n",
        "    ResidualBlock(2, 30),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "ZqTT0AkMnanB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ],
      "metadata": {
        "id": "_LcrqpxCnbxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구성 요소에 기반한 손실과 지표"
      ],
      "metadata": {
        "id": "gwR4ODNPndxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReconstructingRegressor(keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
        "                                          kernel_initializer=\"lecun_normal\")\n",
        "                       for _ in range(5)]\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
        "        #super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        self.recon_loss = 0.05 * tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        \n",
        "        if training:\n",
        "           result = self.reconstruction_mean(recon_loss)\n",
        "           self.add_metric(result)\n",
        "        return self.out(Z)\n",
        "    \n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=[self.recon_loss])\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "R38NL6DHnfpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Qkr-eTj0ngxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ReconstructingRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
        "y_pred = model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "4TW0rzGnnhuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자동 미분을 사용하여 그레디언트 계산하기"
      ],
      "metadata": {
        "id": "scF3rHDUnoCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(w1, w2):\n",
        "    return 3*w1**2 + 2*w1*w2"
      ],
      "metadata": {
        "id": "oivEimJ4np3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2 = 5, 3\n",
        "eps = 1e-6\n",
        "(f(w1 + eps, w2) - f(w1,w2)) / eps"
      ],
      "metadata": {
        "id": "P5bAO-fSnuOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(f(w1, w2 + eps) - f(w1, w2)) / eps"
      ],
      "metadata": {
        "id": "lhF45p77n14I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])"
      ],
      "metadata": {
        "id": "Ly_0D8w-oUT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "id": "a5Ei_tNiogPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "dz_dw1 = tape.gradient(z, w1)\n",
        "try:\n",
        "    dz_dw2 = tape.gradient(z, w2)\n",
        "except RuntimeError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "_NY6XQN1og2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "dz_dw1 = tape.gradient(z, w1)\n",
        "dz_dw2 = tape.gradient(z, w2)\n",
        "del tape"
      ],
      "metadata": {
        "id": "6xg7VzNmo5tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dz_dw1, dz_dw2"
      ],
      "metadata": {
        "id": "cvvHpsWcpSXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])"
      ],
      "metadata": {
        "id": "VpYES7ZopUex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "id": "WMl-8ZQeqTR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(c1)\n",
        "    tape.watch(c2)\n",
        "    z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])"
      ],
      "metadata": {
        "id": "d4QDBrNsqULR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "id": "WZ-pcBOAqVFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "\n",
        "tape.gradient([z1, z2, z3], [w1, w2])"
      ],
      "metadata": {
        "id": "myh9VlJ5qWDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "\n",
        "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
        "del tape"
      ],
      "metadata": {
        "id": "6jAFbl3pqXHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as hessian_tape:\n",
        "    with tf.GradientTape() as jacobian_tape:\n",
        "        z = f(w1, w2)\n",
        "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
        "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
        "            for jacobian in jacobians]\n",
        "del hessian_tape"
      ],
      "metadata": {
        "id": "0sB30u2OqYZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "jacobians"
      ],
      "metadata": {
        "id": "YHITXyK2qZQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hessians"
      ],
      "metadata": {
        "id": "EX7AWDgcqaCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(w1, w2):\n",
        "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "tape.gradient(z, [w1, w2])"
      ],
      "metadata": {
        "id": "0H8Mugo0qa1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(100.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "metadata": {
        "id": "hFpqBdA6qb0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
      ],
      "metadata": {
        "id": "Otnua5kwqdXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([100.])\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "metadata": {
        "id": "OgshaXX3qedg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def my_better_softplus(z):\n",
        "    exp = tf.exp(z)\n",
        "    def my_softplus_gradients(grad):\n",
        "        return grad / (1 + 1 / exp)\n",
        "    return tf.math.log(exp + 1), my_softplus_gradients"
      ],
      "metadata": {
        "id": "Mvbo5d5QqfYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_better_softplus(z):\n",
        "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
      ],
      "metadata": {
        "id": "jT8dFgyAqgqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([1000.])\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_better_softplus(x)\n",
        "\n",
        "z, tape.gradient(z, [x])"
      ],
      "metadata": {
        "id": "fNhaUsCtqhmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자 정의 훈련 반복"
      ],
      "metadata": {
        "id": "4z8RSB8UqkmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "t3Z06y4Vql85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2_reg = keras.regularizers.l2(0.05)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=l2_reg),\n",
        "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ],
      "metadata": {
        "id": "3f2QMGj_qmsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]"
      ],
      "metadata": {
        "id": "QLYZ1E66qn-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "                         for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
        "          end=end)"
      ],
      "metadata": {
        "id": "HZSR_-Fkqo33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
        "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
        "for i in range(1, 50 + 1):\n",
        "    loss = 1 / i\n",
        "    mean_loss(loss)\n",
        "    mean_square(i ** 2)\n",
        "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
        "    time.sleep(0.05)"
      ],
      "metadata": {
        "id": "oVvcx-TEqpqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def progress_bar(iteration, total, size=30):\n",
        "    running = iteration < total\n",
        "    c = \">\" if running else \"=\"\n",
        "    p = (size - 1) * iteration // total\n",
        "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
        "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
        "    return fmt.format(*params)"
      ],
      "metadata": {
        "id": "Rlu6ynqnqqg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar(3500, 10000, size=6)"
      ],
      "metadata": {
        "id": "n8wJTmqiqraW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
        "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "                         for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
      ],
      "metadata": {
        "id": "ioLylmaHqsYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
        "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
        "for i in range(1, 50 + 1):\n",
        "    loss = 1 / i\n",
        "    mean_loss(loss)\n",
        "    mean_square(i ** 2)\n",
        "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
        "    time.sleep(0.05)"
      ],
      "metadata": {
        "id": "ykL3ASfsqtTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "g-KhGHjoquQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.MeanAbsoluteError()]"
      ],
      "metadata": {
        "id": "19M_xAGIqvEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "    for step in range(1, n_steps + 1):\n",
        "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        for variable in model.variables:\n",
        "            if variable.constraint is not None:\n",
        "                variable.assign(variable.constraint(variable))\n",
        "        mean_loss(loss)\n",
        "        for metric in metrics:\n",
        "            metric(y_batch, y_pred)\n",
        "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "    for metric in [mean_loss] + metrics:\n",
        "        metric.reset_states()"
      ],
      "metadata": {
        "id": "6tiCPIVxqv5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from tqdm.notebook import trange\n",
        "    from collections import OrderedDict\n",
        "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "        for epoch in epochs:\n",
        "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
        "                for step in steps:\n",
        "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        y_pred = model(X_batch)\n",
        "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                        loss = tf.add_n([main_loss] + model.losses)\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    for variable in model.variables:\n",
        "                        if variable.constraint is not None:\n",
        "                            variable.assign(variable.constraint(variable))                    \n",
        "                    status = OrderedDict()\n",
        "                    mean_loss(loss)\n",
        "                    status[\"loss\"] = mean_loss.result().numpy()\n",
        "                    for metric in metrics:\n",
        "                        metric(y_batch, y_pred)\n",
        "                        status[metric.name] = metric.result().numpy()\n",
        "                    steps.set_postfix(status)\n",
        "            for metric in [mean_loss] + metrics:\n",
        "                metric.reset_states()\n",
        "except ImportError as ex:\n",
        "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
      ],
      "metadata": {
        "id": "UmPQOYcPqxb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서플로 함수"
      ],
      "metadata": {
        "id": "k1BygiXnqzqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cube(x):\n",
        "    return x ** 3"
      ],
      "metadata": {
        "id": "svvFFVHIq0nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cube(2)"
      ],
      "metadata": {
        "id": "6pyfG8O9q14w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cube(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "pm9HJA1eq3Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube = tf.function(cube)\n",
        "tf_cube"
      ],
      "metadata": {
        "id": "UQwjTUX8q32A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube(2)"
      ],
      "metadata": {
        "id": "9VHqAMrWq4qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "5mempp-Rq5Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> TF 함수와 콘크리트 함수"
      ],
      "metadata": {
        "id": "bxgYpXJUq7Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
        "concrete_function.graph"
      ],
      "metadata": {
        "id": "u6EpDUH9q96y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "U7xiyz6bq-rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "dJP4WHN_q_jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> 함수 정의와 그래프"
      ],
      "metadata": {
        "id": "9WQlOXMXrBA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function.graph"
      ],
      "metadata": {
        "id": "wu_AsFV9rEKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ops = concrete_function.graph.get_operations()\n",
        "ops"
      ],
      "metadata": {
        "id": "jOp4cqYKrFHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pow_op = ops[2]\n",
        "list(pow_op.inputs)"
      ],
      "metadata": {
        "id": "ISDQiSAOreAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pow_op.outputs"
      ],
      "metadata": {
        "id": "_tYmLRzbrfEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function.graph.get_operation_by_name('x')"
      ],
      "metadata": {
        "id": "3QFTmlBBriK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function.graph.get_tensor_by_name('Identity:0')"
      ],
      "metadata": {
        "id": "l_HFDPZCri_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_function.function_def.signature"
      ],
      "metadata": {
        "id": "NhwpXk0grjvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> TF 함수가 계산 그래프를 추출하기 위해 파이썬 함수를 트레이싱하는 방법"
      ],
      "metadata": {
        "id": "teEWnnayrmIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def tf_cube(x):\n",
        "    print(\"print:\", x)\n",
        "    return x ** 3"
      ],
      "metadata": {
        "id": "mrzr411Trp87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tf_cube(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "MmqNmAZOrtSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "UpRUBwo_ruFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tf_cube(2)\n",
        "result = tf_cube(3)\n",
        "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
        "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
        "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!"
      ],
      "metadata": {
        "id": "wFnprUYlrvWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
        "def shrink(images):\n",
        "    print(\"트레이싱\", images)\n",
        "    return images[:, ::2, ::2]"
      ],
      "metadata": {
        "id": "NE72qVoWrwUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "3NmCGI9Mryew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
        "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
        "preprocessed_images = shrink(img_batch_1)\n",
        "preprocessed_images = shrink(img_batch_2)"
      ],
      "metadata": {
        "id": "1QEwnvoWrz5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
        "try:\n",
        "    preprocessed_images = shrink(img_batch_3)  # 다른 타입이나 크기 거부\n",
        "except ValueError as ex:\n",
        "    print(ex)"
      ],
      "metadata": {
        "id": "S6HvbNaxr1bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> 오토그래프를 사용해 제어 흐름 나타내기"
      ],
      "metadata": {
        "id": "P0Lnn2ifr5Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add_10(x):\n",
        "    for i in range(10):\n",
        "        x += 1\n",
        "    return x"
      ],
      "metadata": {
        "id": "3ESGI7RGvr26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_10(tf.constant(5))"
      ],
      "metadata": {
        "id": "ix4dS7q4vs2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
      ],
      "metadata": {
        "id": "pr7G8Su0vuB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add_10(x):\n",
        "    condition = lambda i, x: tf.less(i, 10)\n",
        "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
        "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
        "    return final_x"
      ],
      "metadata": {
        "id": "Y_4-oNyPv_mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_10(tf.constant(5))"
      ],
      "metadata": {
        "id": "EcSV_L7AwA52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
      ],
      "metadata": {
        "id": "AcwHgpXXwBvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add_10(x):\n",
        "    for i in tf.range(10):\n",
        "        x = x + 1\n",
        "    return x"
      ],
      "metadata": {
        "id": "iLyPMPiTwHGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
      ],
      "metadata": {
        "id": "3uaZEsQLwH9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> TF 함수에서 변수와 다른 자원 다루기"
      ],
      "metadata": {
        "id": "nuKTQDn4wKKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = tf.Variable(0)\n",
        "\n",
        "@tf.function\n",
        "def increment(counter, c=1):\n",
        "    return counter.assign_add(c)"
      ],
      "metadata": {
        "id": "_ksHViMVwM4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "increment(counter)\n",
        "increment(counter)"
      ],
      "metadata": {
        "id": "O1nfj0gFwNz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function_def = increment.get_concrete_function(counter).function_def\n",
        "function_def.signature.input_arg[0]"
      ],
      "metadata": {
        "id": "dnD3-A8UwOq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter = tf.Variable(0)\n",
        "\n",
        "@tf.function\n",
        "def increment(c=1):\n",
        "    return counter.assign_add(c)"
      ],
      "metadata": {
        "id": "-e_52fY5wPkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "increment()\n",
        "increment()"
      ],
      "metadata": {
        "id": "2ff6ZP1nwQkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function_def = increment.get_concrete_function().function_def\n",
        "function_def.signature.input_arg[0]"
      ],
      "metadata": {
        "id": "b-ivJ8lvwRi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Counter:\n",
        "    def __init__(self):\n",
        "        self.counter = tf.Variable(0)\n",
        "\n",
        "    @tf.function\n",
        "    def increment(self, c=1):\n",
        "        return self.counter.assign_add(c)"
      ],
      "metadata": {
        "id": "0or5lI1nyhM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Counter()\n",
        "c.increment()\n",
        "c.increment()"
      ],
      "metadata": {
        "id": "nNN9Adenyiom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add_10(x):\n",
        "    for i in tf.range(10):\n",
        "        x += 1\n",
        "    return x\n",
        "\n",
        "print(tf.autograph.to_code(add_10.python_function))"
      ],
      "metadata": {
        "id": "nOGbdtQWykce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_tf_code(func):\n",
        "    from IPython.display import display, Markdown\n",
        "    if hasattr(func, \"python_function\"):\n",
        "        func = func.python_function\n",
        "    code = tf.autograph.to_code(func)\n",
        "    display(Markdown('```python\\n{}\\n```'.format(code)))"
      ],
      "metadata": {
        "id": "HZSv0oBhylRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tf_code(add_10)"
      ],
      "metadata": {
        "id": "19vstwuYymnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tf.keras와 TF 함수를 함께 사용하거나 사용하지 않기"
      ],
      "metadata": {
        "id": "JbeZPtoG0rZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_mse(y_true, y_pred):\n",
        "    print(\"my_mse() 손실 트레이싱\")\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))"
      ],
      "metadata": {
        "id": "kQHyPCj30uxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_mae(y_true, y_pred):\n",
        "    print(\"my_mae() 지표 트레이싱\")\n",
        "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
      ],
      "metadata": {
        "id": "VWdENVMw0w7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(input_shape[1], self.units),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        self.biases = self.add_weight(name='bias', \n",
        "                                      shape=(self.units,),\n",
        "                                      initializer='zeros',\n",
        "                                      trainable=True)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        print(\"MyDense.call() 트레이싱\")\n",
        "        return self.activation(X @ self.kernel + self.biases)"
      ],
      "metadata": {
        "id": "E8niN3gv0yAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "rpUcJJ5W0zK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(keras.models.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
        "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
        "        self.output_ = MyDense(1)\n",
        "\n",
        "    def call(self, input):\n",
        "        print(\"MyModel.call() 트레이싱\")\n",
        "        hidden1 = self.hidden1(input)\n",
        "        hidden2 = self.hidden2(hidden1)\n",
        "        concat = keras.layers.concatenate([input, hidden2])\n",
        "        output = self.output_(concat)\n",
        "        return output\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "rCx_abX000U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
      ],
      "metadata": {
        "id": "Uf8JtIJi027_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "uSWtZLyj03ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "wX1DTEHX04nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(dynamic=True)"
      ],
      "metadata": {
        "id": "n8K6enrw05w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
      ],
      "metadata": {
        "id": "0xGqYo6C060A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
        "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
        "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
      ],
      "metadata": {
        "id": "OBGTSOBp07io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "wPo8jEjF08iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()"
      ],
      "metadata": {
        "id": "eFpDXpDg0-M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
      ],
      "metadata": {
        "id": "JK0EjyZX0_Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
        "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
        "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
      ],
      "metadata": {
        "id": "0E5xkQ281AD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자 정의 옵티마이저"
      ],
      "metadata": {
        "id": "7JkQO1-i1C6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
        "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
        "        \"\"\"super().__init__()를 호출하고 _set_hyper()를 사용해 하이퍼파라미터를 저장합니다\"\"\"\n",
        "        super().__init__(name, **kwargs)\n",
        "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # lr=learning_rate을 처리\n",
        "        self._set_hyper(\"decay\", self._initial_decay) # \n",
        "        self._set_hyper(\"momentum\", momentum)\n",
        "    \n",
        "    def _create_slots(self, var_list):\n",
        "        \"\"\"모델 파라미터마다 연관된 옵티마이저 변수를 만듭니다.\n",
        "        텐서플로는 이런 옵티마이저 변수를 '슬롯'이라고 부릅니다.\n",
        "        모멘텀 옵티마이저에서는 모델 파라미터마다 하나의 모멘텀 슬롯이 필요합니다.\n",
        "        \"\"\"\n",
        "        for var in var_list:\n",
        "            self.add_slot(var, \"momentum\")\n",
        "\n",
        "    @tf.function\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        \"\"\"슬롯을 업데이트하고 모델 파라미터에 대한 옵티마이저 스텝을 수행합니다.\n",
        "        \"\"\"\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype) # 학습률 감쇠 처리\n",
        "        momentum_var = self.get_slot(var, \"momentum\")\n",
        "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
        "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
        "        var.assign_add(momentum_var * lr_t)\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
        "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
        "        }"
      ],
      "metadata": {
        "id": "X3aWdoTI1EYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "QGpHiRl61GoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
        "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
        "model.fit(X_train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "Y9_Xp_3_1LPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 연습문제\n",
        "<h2> 12.\n",
        "<h2> b."
      ],
      "metadata": {
        "id": "bDpWF5Ms15pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(keras.layers.Layer):\n",
        "    def __init__(self, eps=0.001, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.alpha = self.add_weight(\n",
        "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
        "            initializer=\"ones\")\n",
        "        self.beta = self.add_weight(\n",
        "            name=\"beta\", shape=batch_input_shape[-1:],\n",
        "            initializer=\"zeros\")\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
        "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return batch_input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"eps\": self.eps}"
      ],
      "metadata": {
        "id": "JDCIF2a32AN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> c."
      ],
      "metadata": {
        "id": "F2t1FNRU2Ddi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train.astype(np.float32)\n",
        "\n",
        "custom_layer_norm = LayerNormalization()\n",
        "keras_layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
        "    keras_layer_norm(X), custom_layer_norm(X)))"
      ],
      "metadata": {
        "id": "eNJ5X2aZ2EZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_alpha = np.random.rand(X.shape[-1])\n",
        "random_beta = np.random.rand(X.shape[-1])\n",
        "\n",
        "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
        "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
        "\n",
        "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
        "    keras_layer_norm(X), custom_layer_norm(X)))"
      ],
      "metadata": {
        "id": "xmAvB5C_2Fef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.\n",
        "<h3> a."
      ],
      "metadata": {
        "id": "Xhgiwtvz2JLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test.astype(np.float32) / 255."
      ],
      "metadata": {
        "id": "VkGb-KqQ2LO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Ou8ai8Q82MWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "6jIF66hK2Njw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
      ],
      "metadata": {
        "id": "3v3OcB5W2POP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "    for epoch in epochs:\n",
        "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
        "            for step in steps:\n",
        "                X_batch, y_batch = random_batch(X_train, y_train)\n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = model(X_batch)\n",
        "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                    loss = tf.add_n([main_loss] + model.losses)\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                for variable in model.variables:\n",
        "                    if variable.constraint is not None:\n",
        "                        variable.assign(variable.constraint(variable))                    \n",
        "                status = OrderedDict()\n",
        "                mean_loss(loss)\n",
        "                status[\"loss\"] = mean_loss.result().numpy()\n",
        "                for metric in metrics:\n",
        "                    metric(y_batch, y_pred)\n",
        "                    status[metric.name] = metric.result().numpy()\n",
        "                steps.set_postfix(status)\n",
        "            y_pred = model(X_valid)\n",
        "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
        "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
        "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
        "            steps.set_postfix(status)\n",
        "        for metric in [mean_loss] + metrics:\n",
        "            metric.reset_states()"
      ],
      "metadata": {
        "id": "9XqptMrq2QOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> b."
      ],
      "metadata": {
        "id": "scKnSlzM2WMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "lBbw42Hv2W4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_layers = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "])\n",
        "upper_layers = keras.models.Sequential([\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model = keras.models.Sequential([\n",
        "    lower_layers, upper_layers\n",
        "])"
      ],
      "metadata": {
        "id": "gDZ3uYx42Xxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
        "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "NR1I4NfX2YsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
      ],
      "metadata": {
        "id": "_cHs499Q2Zq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "    for epoch in epochs:\n",
        "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
        "            for step in steps:\n",
        "                X_batch, y_batch = random_batch(X_train, y_train)\n",
        "                with tf.GradientTape(persistent=True) as tape:\n",
        "                    y_pred = model(X_batch)\n",
        "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                    loss = tf.add_n([main_loss] + model.losses)\n",
        "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
        "                                          (upper_layers, upper_optimizer)):\n",
        "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
        "                del tape\n",
        "                for variable in model.variables:\n",
        "                    if variable.constraint is not None:\n",
        "                        variable.assign(variable.constraint(variable))                    \n",
        "                status = OrderedDict()\n",
        "                mean_loss(loss)\n",
        "                status[\"loss\"] = mean_loss.result().numpy()\n",
        "                for metric in metrics:\n",
        "                    metric(y_batch, y_pred)\n",
        "                    status[metric.name] = metric.result().numpy()\n",
        "                steps.set_postfix(status)\n",
        "            y_pred = model(X_valid)\n",
        "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
        "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
        "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
        "            steps.set_postfix(status)\n",
        "        for metric in [mean_loss] + metrics:\n",
        "            metric.reset_states()"
      ],
      "metadata": {
        "id": "FgOaJY-r2asw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hLzMNLsx2btP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}